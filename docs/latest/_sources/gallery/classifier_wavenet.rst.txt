
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "gallery/classifier_wavenet.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_gallery_classifier_wavenet.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_gallery_classifier_wavenet.py:


DenseNet Classifier: Detecting Regions of Interest in Synthetic Signals
======================================================================

This example demonstrates how to use DeepPeak's DenseNet classifier to identify
regions of interest (ROIs) in synthetic 1D signals containing Gaussian peaks.

We will:
- Generate a dataset of noisy signals with random Gaussian peaks
- Build and train a DenseNet classifier to detect ROIs
- Visualize the training process and model predictions

.. note::
    This example is fully reproducible and suitable for Sphinx-Gallery documentation.

.. GENERATED FROM PYTHON SOURCE LINES 19-21

Imports and reproducibility
--------------------------

.. GENERATED FROM PYTHON SOURCE LINES 21-28

.. code-block:: Python

    import numpy as np

    from DeepPeak.machine_learning.classifier import WaveNet
    from DeepPeak.signals import Kernel, SignalDatasetGenerator

    np.random.seed(42)








.. GENERATED FROM PYTHON SOURCE LINES 29-31

Generate synthetic dataset
-------------------------

.. GENERATED FROM PYTHON SOURCE LINES 31-47

.. code-block:: Python

    NUM_PEAKS = 3
    SEQUENCE_LENGTH = 200

    generator = SignalDatasetGenerator(n_samples=100, sequence_length=SEQUENCE_LENGTH)

    dataset = generator.generate(
        signal_type=Kernel.GAUSSIAN,
        n_peaks=(1, NUM_PEAKS),
        amplitude=(1, 20),
        position=(0.1, 0.9),
        width=(0.03, 0.05),
        noise_std=0.1,
        categorical_peak_count=False,
        compute_region_of_interest=True,
    )








.. GENERATED FROM PYTHON SOURCE LINES 48-50

Visualize a few example signals and their regions of interest
------------------------------------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 50-52

.. code-block:: Python

    dataset.plot(number_of_samples=3)




.. image-sg:: /gallery/images/sphx_glr_classifier_wavenet_001.png
   :alt: classifier wavenet
   :srcset: /gallery/images/sphx_glr_classifier_wavenet_001.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 53-55

Build and summarize the WaveNet classifier
------------------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 55-67

.. code-block:: Python

    dense_net = WaveNet(
        sequence_length=SEQUENCE_LENGTH,
        num_filters=64,
        num_dilation_layers=6,
        kernel_size=3,
        optimizer="adam",
        loss="binary_crossentropy",
        metrics=["accuracy"],
    )
    dense_net.build()
    dense_net.summary()





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Model: "WaveNetDetector"
    ┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓
    ┃ Layer (type)        ┃ Output Shape      ┃    Param # ┃ Connected to      ┃
    ┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩
    │ input (InputLayer)  │ (None, 200, 1)    │          0 │ -                 │
    ├─────────────────────┼───────────────────┼────────────┼───────────────────┤
    │ input_projection    │ (None, 200, 64)   │        128 │ input[0][0]       │
    │ (Conv1D)            │                   │            │                   │
    ├─────────────────────┼───────────────────┼────────────┼───────────────────┤
    │ dilated_conv_0      │ (None, 200, 64)   │     12,352 │ input_projection… │
    │ (Conv1D)            │                   │            │                   │
    ├─────────────────────┼───────────────────┼────────────┼───────────────────┤
    │ res_0 (Conv1D)      │ (None, 200, 64)   │      4,160 │ dilated_conv_0[0… │
    ├─────────────────────┼───────────────────┼────────────┼───────────────────┤
    │ residual_add_0      │ (None, 200, 64)   │          0 │ input_projection… │
    │ (Add)               │                   │            │ res_0[0][0]       │
    ├─────────────────────┼───────────────────┼────────────┼───────────────────┤
    │ dilated_conv_1      │ (None, 200, 64)   │     12,352 │ residual_add_0[0… │
    │ (Conv1D)            │                   │            │                   │
    ├─────────────────────┼───────────────────┼────────────┼───────────────────┤
    │ res_1 (Conv1D)      │ (None, 200, 64)   │      4,160 │ dilated_conv_1[0… │
    ├─────────────────────┼───────────────────┼────────────┼───────────────────┤
    │ residual_add_1      │ (None, 200, 64)   │          0 │ residual_add_0[0… │
    │ (Add)               │                   │            │ res_1[0][0]       │
    ├─────────────────────┼───────────────────┼────────────┼───────────────────┤
    │ dilated_conv_2      │ (None, 200, 64)   │     12,352 │ residual_add_1[0… │
    │ (Conv1D)            │                   │            │                   │
    ├─────────────────────┼───────────────────┼────────────┼───────────────────┤
    │ res_2 (Conv1D)      │ (None, 200, 64)   │      4,160 │ dilated_conv_2[0… │
    ├─────────────────────┼───────────────────┼────────────┼───────────────────┤
    │ residual_add_2      │ (None, 200, 64)   │          0 │ residual_add_1[0… │
    │ (Add)               │                   │            │ res_2[0][0]       │
    ├─────────────────────┼───────────────────┼────────────┼───────────────────┤
    │ dilated_conv_3      │ (None, 200, 64)   │     12,352 │ residual_add_2[0… │
    │ (Conv1D)            │                   │            │                   │
    ├─────────────────────┼───────────────────┼────────────┼───────────────────┤
    │ res_3 (Conv1D)      │ (None, 200, 64)   │      4,160 │ dilated_conv_3[0… │
    ├─────────────────────┼───────────────────┼────────────┼───────────────────┤
    │ residual_add_3      │ (None, 200, 64)   │          0 │ residual_add_2[0… │
    │ (Add)               │                   │            │ res_3[0][0]       │
    ├─────────────────────┼───────────────────┼────────────┼───────────────────┤
    │ dilated_conv_4      │ (None, 200, 64)   │     12,352 │ residual_add_3[0… │
    │ (Conv1D)            │                   │            │                   │
    ├─────────────────────┼───────────────────┼────────────┼───────────────────┤
    │ res_4 (Conv1D)      │ (None, 200, 64)   │      4,160 │ dilated_conv_4[0… │
    ├─────────────────────┼───────────────────┼────────────┼───────────────────┤
    │ residual_add_4      │ (None, 200, 64)   │          0 │ residual_add_3[0… │
    │ (Add)               │                   │            │ res_4[0][0]       │
    ├─────────────────────┼───────────────────┼────────────┼───────────────────┤
    │ dilated_conv_5      │ (None, 200, 64)   │     12,352 │ residual_add_4[0… │
    │ (Conv1D)            │                   │            │                   │
    ├─────────────────────┼───────────────────┼────────────┼───────────────────┤
    │ res_5 (Conv1D)      │ (None, 200, 64)   │      4,160 │ dilated_conv_5[0… │
    ├─────────────────────┼───────────────────┼────────────┼───────────────────┤
    │ residual_add_5      │ (None, 200, 64)   │          0 │ residual_add_4[0… │
    │ (Add)               │                   │            │ res_5[0][0]       │
    ├─────────────────────┼───────────────────┼────────────┼───────────────────┤
    │ skip_0 (Conv1D)     │ (None, 200, 64)   │      4,160 │ residual_add_0[0… │
    ├─────────────────────┼───────────────────┼────────────┼───────────────────┤
    │ skip_1 (Conv1D)     │ (None, 200, 64)   │      4,160 │ residual_add_1[0… │
    ├─────────────────────┼───────────────────┼────────────┼───────────────────┤
    │ skip_2 (Conv1D)     │ (None, 200, 64)   │      4,160 │ residual_add_2[0… │
    ├─────────────────────┼───────────────────┼────────────┼───────────────────┤
    │ skip_3 (Conv1D)     │ (None, 200, 64)   │      4,160 │ residual_add_3[0… │
    ├─────────────────────┼───────────────────┼────────────┼───────────────────┤
    │ skip_4 (Conv1D)     │ (None, 200, 64)   │      4,160 │ residual_add_4[0… │
    ├─────────────────────┼───────────────────┼────────────┼───────────────────┤
    │ skip_5 (Conv1D)     │ (None, 200, 64)   │      4,160 │ residual_add_5[0… │
    ├─────────────────────┼───────────────────┼────────────┼───────────────────┤
    │ skip_add (Add)      │ (None, 200, 64)   │          0 │ skip_0[0][0],     │
    │                     │                   │            │ skip_1[0][0],     │
    │                     │                   │            │ skip_2[0][0],     │
    │                     │                   │            │ skip_3[0][0],     │
    │                     │                   │            │ skip_4[0][0],     │
    │                     │                   │            │ skip_5[0][0]      │
    ├─────────────────────┼───────────────────┼────────────┼───────────────────┤
    │ post_relu (ReLU)    │ (None, 200, 64)   │          0 │ skip_add[0][0]    │
    ├─────────────────────┼───────────────────┼────────────┼───────────────────┤
    │ output (Conv1D)     │ (None, 200, 1)    │         65 │ post_relu[0][0]   │
    └─────────────────────┴───────────────────┴────────────┴───────────────────┘
     Total params: 124,225 (485.25 KB)
     Trainable params: 124,225 (485.25 KB)
     Non-trainable params: 0 (0.00 B)




.. GENERATED FROM PYTHON SOURCE LINES 68-70

Train the classifier
--------------------

.. GENERATED FROM PYTHON SOURCE LINES 70-78

.. code-block:: Python

    history = dense_net.fit(
        dataset.signals,
        dataset.region_of_interest,
        validation_split=0.2,
        epochs=20,
        batch_size=64,
    )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Epoch 1/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 4s 4s/step - accuracy: 0.2934 - loss: 1.5383    2/2 ━━━━━━━━━━━━━━━━━━━━ 5s 452ms/step - accuracy: 0.4142 - loss: 1.3474 - val_accuracy: 0.8785 - val_loss: 0.6143
    Epoch 2/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 111ms/step - accuracy: 0.8484 - loss: 0.7838    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 76ms/step - accuracy: 0.8698 - loss: 0.7203 - val_accuracy: 0.9613 - val_loss: 0.4730
    Epoch 3/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 103ms/step - accuracy: 0.9495 - loss: 0.6402    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.9496 - loss: 0.6115 - val_accuracy: 0.9560 - val_loss: 0.2624
    Epoch 4/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 104ms/step - accuracy: 0.9437 - loss: 0.3370    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.9396 - loss: 0.3513 - val_accuracy: 0.9583 - val_loss: 0.1991
    Epoch 5/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 103ms/step - accuracy: 0.9409 - loss: 0.2611    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.9440 - loss: 0.2564 - val_accuracy: 0.9613 - val_loss: 0.1812
    Epoch 6/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 103ms/step - accuracy: 0.9500 - loss: 0.2178    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.9476 - loss: 0.2179 - val_accuracy: 0.9455 - val_loss: 0.1822
    Epoch 7/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 103ms/step - accuracy: 0.9305 - loss: 0.2585    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.9356 - loss: 0.2331 - val_accuracy: 0.9613 - val_loss: 0.1635
    Epoch 8/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 103ms/step - accuracy: 0.9492 - loss: 0.2272    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 76ms/step - accuracy: 0.9499 - loss: 0.2192 - val_accuracy: 0.9700 - val_loss: 0.0772
    Epoch 9/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 102ms/step - accuracy: 0.9576 - loss: 0.1098    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.9568 - loss: 0.1183 - val_accuracy: 0.9670 - val_loss: 0.0904
    Epoch 10/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 104ms/step - accuracy: 0.9524 - loss: 0.1407    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 78ms/step - accuracy: 0.9541 - loss: 0.1336 - val_accuracy: 0.9628 - val_loss: 0.0977
    Epoch 11/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 104ms/step - accuracy: 0.9517 - loss: 0.1468    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 76ms/step - accuracy: 0.9529 - loss: 0.1414 - val_accuracy: 0.9688 - val_loss: 0.0802
    Epoch 12/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 104ms/step - accuracy: 0.9598 - loss: 0.1121    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 78ms/step - accuracy: 0.9594 - loss: 0.1118 - val_accuracy: 0.9695 - val_loss: 0.0834
    Epoch 13/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 102ms/step - accuracy: 0.9526 - loss: 0.1292    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.9529 - loss: 0.1282 - val_accuracy: 0.9728 - val_loss: 0.0662
    Epoch 14/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 102ms/step - accuracy: 0.9648 - loss: 0.0853    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 76ms/step - accuracy: 0.9611 - loss: 0.0965 - val_accuracy: 0.9615 - val_loss: 0.0818
    Epoch 15/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 102ms/step - accuracy: 0.9521 - loss: 0.1106    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 113ms/step - accuracy: 0.9537 - loss: 0.1050 - val_accuracy: 0.9720 - val_loss: 0.0694
    Epoch 16/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 102ms/step - accuracy: 0.9588 - loss: 0.0981    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.9591 - loss: 0.0948 - val_accuracy: 0.9733 - val_loss: 0.0644
    Epoch 17/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 102ms/step - accuracy: 0.9624 - loss: 0.0835    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.9617 - loss: 0.0831 - val_accuracy: 0.9662 - val_loss: 0.0708
    Epoch 18/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 105ms/step - accuracy: 0.9577 - loss: 0.0904    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 76ms/step - accuracy: 0.9568 - loss: 0.0919 - val_accuracy: 0.9740 - val_loss: 0.0610
    Epoch 19/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 103ms/step - accuracy: 0.9631 - loss: 0.0839    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 76ms/step - accuracy: 0.9639 - loss: 0.0806 - val_accuracy: 0.9760 - val_loss: 0.0604
    Epoch 20/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 102ms/step - accuracy: 0.9634 - loss: 0.0850    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.9645 - loss: 0.0814 - val_accuracy: 0.9698 - val_loss: 0.0603




.. GENERATED FROM PYTHON SOURCE LINES 79-81

Plot training history
---------------------

.. GENERATED FROM PYTHON SOURCE LINES 81-83

.. code-block:: Python

    dense_net.plot_model_history()




.. image-sg:: /gallery/images/sphx_glr_classifier_wavenet_002.png
   :alt: accuracy, loss, val_accuracy, val_loss
   :srcset: /gallery/images/sphx_glr_classifier_wavenet_002.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 84-86

Predict and visualize on a test signal
--------------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 86-87

.. code-block:: Python

    dense_net.plot_prediction(signal=dataset.signals[0:1, :], threshold=0.4)



.. image-sg:: /gallery/images/sphx_glr_classifier_wavenet_003.png
   :alt: Predicted Region of Interest
   :srcset: /gallery/images/sphx_glr_classifier_wavenet_003.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    <Figure size 1200x500 with 1 Axes>




.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 10.211 seconds)


.. _sphx_glr_download_gallery_classifier_wavenet.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: classifier_wavenet.ipynb <classifier_wavenet.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: classifier_wavenet.py <classifier_wavenet.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: classifier_wavenet.zip <classifier_wavenet.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
