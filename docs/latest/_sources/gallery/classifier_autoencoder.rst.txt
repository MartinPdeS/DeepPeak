
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "gallery/classifier_autoencoder.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_gallery_classifier_autoencoder.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_gallery_classifier_autoencoder.py:


DenseNet Classifier: Detecting Regions of Interest in Synthetic Signals
=======================================================================

This example demonstrates how to use DeepPeak's DenseNet classifier to identify
regions of interest (ROIs) in synthetic 1D signals containing Gaussian peaks.

We will:
- Generate a dataset of noisy signals with random Gaussian peaks
- Build and train a DenseNet classifier to detect ROIs
- Visualize the training process and model predictions

.. note::
    This example is fully reproducible and suitable for Sphinx-Gallery documentation.

.. GENERATED FROM PYTHON SOURCE LINES 19-21

Imports and reproducibility
--------------------------

.. GENERATED FROM PYTHON SOURCE LINES 21-29

.. code-block:: Python

    import numpy as np

    from DeepPeak.machine_learning.classifier import Autoencoder, BinaryIoU
    from DeepPeak.signals import SignalDatasetGenerator
    from DeepPeak import kernel

    np.random.seed(42)








.. GENERATED FROM PYTHON SOURCE LINES 30-32

Generate synthetic dataset
-------------------------

.. GENERATED FROM PYTHON SOURCE LINES 32-51

.. code-block:: Python

    NUM_PEAKS = 3
    SEQUENCE_LENGTH = 200

    kernel = kernel.Lorentzian(
        amplitude=(1, 20),
        position=(0.1, 0.9),
        width=(0.03, 0.05),
    )

    generator = SignalDatasetGenerator(n_samples=100, sequence_length=SEQUENCE_LENGTH)

    dataset = generator.generate(
        kernel=kernel,
        n_peaks=(1, NUM_PEAKS),
        noise_std=0.1,
        categorical_peak_count=False,
        compute_region_of_interest=True,
    )








.. GENERATED FROM PYTHON SOURCE LINES 52-54

Visualize a few example signals and their regions of interest
------------------------------------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 54-56

.. code-block:: Python

    dataset.plot(number_of_samples=3)




.. image-sg:: /gallery/images/sphx_glr_classifier_autoencoder_001.png
   :alt: Predicted ROI (Sample 0), Predicted ROI (Sample 1), Predicted ROI (Sample 2)
   :srcset: /gallery/images/sphx_glr_classifier_autoencoder_001.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    <Figure size 800x900 with 3 Axes>



.. GENERATED FROM PYTHON SOURCE LINES 57-59

Build and summarize the WaveNet classifier
------------------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 59-73

.. code-block:: Python

    dense_net = Autoencoder(
        sequence_length=SEQUENCE_LENGTH,
        dropout_rate=0.30,
        filters=(32, 64, 128),
        kernel_size=3,
        pool_size=2,
        upsample_size=2,
        optimizer="adam",
        loss="binary_crossentropy",
        metrics=[BinaryIoU(threshold=0.5)],
    )
    dense_net.build()
    dense_net.summary()





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Model: "AutoencoderROILocator"
    ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
    ┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
    ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
    │ input (InputLayer)              │ (None, 200, 1)         │             0 │
    ├─────────────────────────────────┼────────────────────────┼───────────────┤
    │ enc_conv0 (Conv1D)              │ (None, 200, 32)        │           128 │
    ├─────────────────────────────────┼────────────────────────┼───────────────┤
    │ enc_drop0 (Dropout)             │ (None, 200, 32)        │             0 │
    ├─────────────────────────────────┼────────────────────────┼───────────────┤
    │ enc_pool0 (MaxPooling1D)        │ (None, 100, 32)        │             0 │
    ├─────────────────────────────────┼────────────────────────┼───────────────┤
    │ enc_conv1 (Conv1D)              │ (None, 100, 64)        │         6,208 │
    ├─────────────────────────────────┼────────────────────────┼───────────────┤
    │ enc_drop1 (Dropout)             │ (None, 100, 64)        │             0 │
    ├─────────────────────────────────┼────────────────────────┼───────────────┤
    │ enc_pool1 (MaxPooling1D)        │ (None, 50, 64)         │             0 │
    ├─────────────────────────────────┼────────────────────────┼───────────────┤
    │ bottleneck_conv (Conv1D)        │ (None, 50, 128)        │        24,704 │
    ├─────────────────────────────────┼────────────────────────┼───────────────┤
    │ bottleneck_drop (Dropout)       │ (None, 50, 128)        │             0 │
    ├─────────────────────────────────┼────────────────────────┼───────────────┤
    │ dec_up0 (UpSampling1D)          │ (None, 100, 128)       │             0 │
    ├─────────────────────────────────┼────────────────────────┼───────────────┤
    │ dec_conv0 (Conv1D)              │ (None, 100, 64)        │        24,640 │
    ├─────────────────────────────────┼────────────────────────┼───────────────┤
    │ dec_up1 (UpSampling1D)          │ (None, 200, 64)        │             0 │
    ├─────────────────────────────────┼────────────────────────┼───────────────┤
    │ dec_conv1 (Conv1D)              │ (None, 200, 32)        │         6,176 │
    ├─────────────────────────────────┼────────────────────────┼───────────────┤
    │ ROI (Conv1D)                    │ (None, 200, 1)         │            33 │
    └─────────────────────────────────┴────────────────────────┴───────────────┘
     Total params: 61,889 (241.75 KB)
     Trainable params: 61,889 (241.75 KB)
     Non-trainable params: 0 (0.00 B)




.. GENERATED FROM PYTHON SOURCE LINES 74-76

Train the classifier
--------------------

.. GENERATED FROM PYTHON SOURCE LINES 76-84

.. code-block:: Python

    history = dense_net.fit(
        dataset.signals,
        dataset.region_of_interest,
        validation_split=0.2,
        epochs=20,
        batch_size=64,
    )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Epoch 1/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 1s 2s/step - BinaryIoU: 0.0475 - loss: 0.6877
    Epoch 1: val_loss improved from None to 0.62996, saving model to /tmp/wavenet_ckpt_r8xel99f/best.weights.h5
        2/2 ━━━━━━━━━━━━━━━━━━━━ 2s 361ms/step - BinaryIoU: 0.0458 - loss: 0.6752 - val_BinaryIoU: 0.0000e+00 - val_loss: 0.6300
    Epoch 2/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 41ms/step - BinaryIoU: 0.0000e+00 - loss: 0.6150
    Epoch 2: val_loss improved from 0.62996 to 0.60419, saving model to /tmp/wavenet_ckpt_r8xel99f/best.weights.h5
        2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 93ms/step - BinaryIoU: 0.0000e+00 - loss: 0.6139 - val_BinaryIoU: 0.0000e+00 - val_loss: 0.6042
    Epoch 3/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 42ms/step - BinaryIoU: 0.0000e+00 - loss: 0.5966
    Epoch 3: val_loss improved from 0.60419 to 0.59329, saving model to /tmp/wavenet_ckpt_r8xel99f/best.weights.h5
        2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 93ms/step - BinaryIoU: 0.0000e+00 - loss: 0.5975 - val_BinaryIoU: 0.0000e+00 - val_loss: 0.5933
    Epoch 4/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - BinaryIoU: 0.0000e+00 - loss: 0.5732
    Epoch 4: val_loss improved from 0.59329 to 0.58227, saving model to /tmp/wavenet_ckpt_r8xel99f/best.weights.h5
        2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 93ms/step - BinaryIoU: 0.0000e+00 - loss: 0.5681 - val_BinaryIoU: 0.0000e+00 - val_loss: 0.5823
    Epoch 5/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 42ms/step - BinaryIoU: 0.0000e+00 - loss: 0.5387
    Epoch 5: val_loss improved from 0.58227 to 0.54779, saving model to /tmp/wavenet_ckpt_r8xel99f/best.weights.h5
        2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 89ms/step - BinaryIoU: 0.0000e+00 - loss: 0.5373 - val_BinaryIoU: 0.0000e+00 - val_loss: 0.5478
    Epoch 6/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - BinaryIoU: 0.0000e+00 - loss: 0.5005
    Epoch 6: val_loss improved from 0.54779 to 0.48315, saving model to /tmp/wavenet_ckpt_r8xel99f/best.weights.h5
        2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 90ms/step - BinaryIoU: 0.0000e+00 - loss: 0.4950 - val_BinaryIoU: 0.0000e+00 - val_loss: 0.4831
    Epoch 7/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - BinaryIoU: 0.0015 - loss: 0.4553
    Epoch 7: val_loss improved from 0.48315 to 0.41717, saving model to /tmp/wavenet_ckpt_r8xel99f/best.weights.h5
        2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 90ms/step - BinaryIoU: 0.0012 - loss: 0.4488 - val_BinaryIoU: 0.1484 - val_loss: 0.4172
    Epoch 8/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 39ms/step - BinaryIoU: 0.0110 - loss: 0.4037
    Epoch 8: val_loss improved from 0.41717 to 0.37200, saving model to /tmp/wavenet_ckpt_r8xel99f/best.weights.h5
        2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 90ms/step - BinaryIoU: 0.0161 - loss: 0.3954 - val_BinaryIoU: 0.5971 - val_loss: 0.3720
    Epoch 9/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - BinaryIoU: 0.2020 - loss: 0.3136
    Epoch 9: val_loss improved from 0.37200 to 0.28677, saving model to /tmp/wavenet_ckpt_r8xel99f/best.weights.h5
        2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 90ms/step - BinaryIoU: 0.2267 - loss: 0.3075 - val_BinaryIoU: 0.5141 - val_loss: 0.2868
    Epoch 10/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 39ms/step - BinaryIoU: 0.2835 - loss: 0.2435
    Epoch 10: val_loss improved from 0.28677 to 0.17883, saving model to /tmp/wavenet_ckpt_r8xel99f/best.weights.h5
        2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 90ms/step - BinaryIoU: 0.3017 - loss: 0.2323 - val_BinaryIoU: 0.5345 - val_loss: 0.1788
    Epoch 11/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 39ms/step - BinaryIoU: 0.3174 - loss: 0.1786
    Epoch 11: val_loss improved from 0.17883 to 0.14196, saving model to /tmp/wavenet_ckpt_r8xel99f/best.weights.h5
        2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 90ms/step - BinaryIoU: 0.3209 - loss: 0.1660 - val_BinaryIoU: 0.4291 - val_loss: 0.1420
    Epoch 12/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - BinaryIoU: 0.4482 - loss: 0.1250
    Epoch 12: val_loss improved from 0.14196 to 0.12198, saving model to /tmp/wavenet_ckpt_r8xel99f/best.weights.h5
        2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 90ms/step - BinaryIoU: 0.4486 - loss: 0.1266 - val_BinaryIoU: 0.3794 - val_loss: 0.1220
    Epoch 13/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - BinaryIoU: 0.4561 - loss: 0.1053
    Epoch 13: val_loss improved from 0.12198 to 0.09085, saving model to /tmp/wavenet_ckpt_r8xel99f/best.weights.h5
        2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 92ms/step - BinaryIoU: 0.4528 - loss: 0.1062 - val_BinaryIoU: 0.4401 - val_loss: 0.0909
    Epoch 14/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 39ms/step - BinaryIoU: 0.4478 - loss: 0.1055
    Epoch 14: val_loss improved from 0.09085 to 0.08907, saving model to /tmp/wavenet_ckpt_r8xel99f/best.weights.h5
        2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 90ms/step - BinaryIoU: 0.4441 - loss: 0.1064 - val_BinaryIoU: 0.4425 - val_loss: 0.0891
    Epoch 15/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - BinaryIoU: 0.5105 - loss: 0.0823
    Epoch 15: val_loss did not improve from 0.08907
        2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - BinaryIoU: 0.5030 - loss: 0.0859 - val_BinaryIoU: 0.4489 - val_loss: 0.0901
    Epoch 16/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - BinaryIoU: 0.4442 - loss: 0.0976
    Epoch 16: val_loss improved from 0.08907 to 0.08446, saving model to /tmp/wavenet_ckpt_r8xel99f/best.weights.h5
        2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 90ms/step - BinaryIoU: 0.4312 - loss: 0.0942 - val_BinaryIoU: 0.1514 - val_loss: 0.0845
    Epoch 17/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - BinaryIoU: 0.3391 - loss: 0.0910
    Epoch 17: val_loss improved from 0.08446 to 0.08088, saving model to /tmp/wavenet_ckpt_r8xel99f/best.weights.h5
        2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 91ms/step - BinaryIoU: 0.3279 - loss: 0.0913 - val_BinaryIoU: 0.0984 - val_loss: 0.0809
    Epoch 18/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 41ms/step - BinaryIoU: 0.2049 - loss: 0.0894
    Epoch 18: val_loss improved from 0.08088 to 0.07862, saving model to /tmp/wavenet_ckpt_r8xel99f/best.weights.h5
        2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 92ms/step - BinaryIoU: 0.2140 - loss: 0.0844 - val_BinaryIoU: 0.1724 - val_loss: 0.0786
    Epoch 19/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - BinaryIoU: 0.2497 - loss: 0.0811
    Epoch 19: val_loss improved from 0.07862 to 0.07486, saving model to /tmp/wavenet_ckpt_r8xel99f/best.weights.h5
        2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 92ms/step - BinaryIoU: 0.2497 - loss: 0.0789 - val_BinaryIoU: 0.5426 - val_loss: 0.0749
    Epoch 20/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 41ms/step - BinaryIoU: 0.3798 - loss: 0.0837
    Epoch 20: val_loss improved from 0.07486 to 0.07217, saving model to /tmp/wavenet_ckpt_r8xel99f/best.weights.h5
        2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 94ms/step - BinaryIoU: 0.4023 - loss: 0.0814 - val_BinaryIoU: 0.5885 - val_loss: 0.0722
    Restored best model weights from /tmp/wavenet_ckpt_r8xel99f/best.weights.h5




.. GENERATED FROM PYTHON SOURCE LINES 85-87

Plot training history
---------------------

.. GENERATED FROM PYTHON SOURCE LINES 87-89

.. code-block:: Python

    dense_net.plot_model_history(filter_pattern="BinaryIoU")




.. image-sg:: /gallery/images/sphx_glr_classifier_autoencoder_002.png
   :alt: BinaryIoU
   :srcset: /gallery/images/sphx_glr_classifier_autoencoder_002.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    <Figure size 800x300 with 1 Axes>



.. GENERATED FROM PYTHON SOURCE LINES 90-92

Predict and visualize on a test signal
--------------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 92-93

.. code-block:: Python

    _ = dense_net.plot_prediction(dataset=dataset, number_of_samples=12, number_of_columns=3, threshold=0.1, randomize_signal=True)



.. image-sg:: /gallery/images/sphx_glr_classifier_autoencoder_003.png
   :alt: Predicted ROI (Sample 6), Predicted ROI (Sample 80), Predicted ROI (Sample 91), Predicted ROI (Sample 81), Predicted ROI (Sample 82), Predicted ROI (Sample 98), Predicted ROI (Sample 78), Predicted ROI (Sample 73), Predicted ROI (Sample 59), Predicted ROI (Sample 48), Predicted ROI (Sample 75), Predicted ROI (Sample 38)
   :srcset: /gallery/images/sphx_glr_classifier_autoencoder_003.png
   :class: sphx-glr-single-img






.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 11.618 seconds)


.. _sphx_glr_download_gallery_classifier_autoencoder.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: classifier_autoencoder.ipynb <classifier_autoencoder.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: classifier_autoencoder.py <classifier_autoencoder.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: classifier_autoencoder.zip <classifier_autoencoder.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
