
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "gallery/classifier_autoencoder.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_gallery_classifier_autoencoder.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_gallery_classifier_autoencoder.py:


DenseNet Classifier: Detecting Regions of Interest in Synthetic Signals
=======================================================================

This example demonstrates how to use DeepPeak's DenseNet classifier to identify
regions of interest (ROIs) in synthetic 1D signals containing Gaussian peaks.

We will:
- Generate a dataset of noisy signals with random Gaussian peaks
- Build and train a DenseNet classifier to detect ROIs
- Visualize the training process and model predictions

.. note::
    This example is fully reproducible and suitable for Sphinx-Gallery documentation.

.. GENERATED FROM PYTHON SOURCE LINES 19-21

Imports and reproducibility
--------------------------

.. GENERATED FROM PYTHON SOURCE LINES 21-29

.. code-block:: Python

    import numpy as np

    from DeepPeak.machine_learning.classifier import Autoencoder, BinaryIoU
    from DeepPeak.signals import SignalDatasetGenerator
    from DeepPeak import kernel

    np.random.seed(42)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    /opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.
      if not hasattr(np, "object"):




.. GENERATED FROM PYTHON SOURCE LINES 30-32

Generate synthetic dataset
-------------------------

.. GENERATED FROM PYTHON SOURCE LINES 32-53

.. code-block:: Python

    NUM_PEAKS = 3
    SEQUENCE_LENGTH = 200

    kernel = kernel.Lorentzian(
        amplitude=(1, 20),
        position=(0.1, 0.9),
        width=(0.03, 0.05),
    )

    generator = SignalDatasetGenerator(sequence_length=SEQUENCE_LENGTH)

    dataset = generator.generate(
        n_samples=100,
        kernel=kernel,
        n_peaks=(1, NUM_PEAKS),
        noise_std=0.1,
        categorical_peak_count=False,
    )

    dataset.compute_region_of_interest(width_in_pixels=5)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    DataSet(signals, amplitudes, positions, widths, labels, x_values, num_peaks)



.. GENERATED FROM PYTHON SOURCE LINES 54-56

Visualize a few example signals and their regions of interest
------------------------------------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 56-58

.. code-block:: Python

    dataset.plot(number_of_samples=3)




.. image-sg:: /gallery/images/sphx_glr_classifier_autoencoder_001.png
   :alt: Sample 0, Sample 1, Sample 2
   :srcset: /gallery/images/sphx_glr_classifier_autoencoder_001.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    <Figure size 800x900 with 3 Axes>



.. GENERATED FROM PYTHON SOURCE LINES 59-61

Build and summarize the WaveNet classifier
------------------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 61-75

.. code-block:: Python

    dense_net = Autoencoder(
        sequence_length=SEQUENCE_LENGTH,
        dropout_rate=0.30,
        filters=(32, 64, 128),
        kernel_size=3,
        pool_size=2,
        upsample_size=2,
        optimizer="adam",
        loss="binary_crossentropy",
        metrics=[BinaryIoU(threshold=0.5)],
    )
    dense_net.build()
    dense_net.summary()





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Model: "AutoencoderROILocator"
    ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
    ┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
    ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
    │ input (InputLayer)              │ (None, 200, 1)         │             0 │
    ├─────────────────────────────────┼────────────────────────┼───────────────┤
    │ enc_conv0 (Conv1D)              │ (None, 200, 32)        │           128 │
    ├─────────────────────────────────┼────────────────────────┼───────────────┤
    │ enc_drop0 (Dropout)             │ (None, 200, 32)        │             0 │
    ├─────────────────────────────────┼────────────────────────┼───────────────┤
    │ enc_pool0 (MaxPooling1D)        │ (None, 100, 32)        │             0 │
    ├─────────────────────────────────┼────────────────────────┼───────────────┤
    │ enc_conv1 (Conv1D)              │ (None, 100, 64)        │         6,208 │
    ├─────────────────────────────────┼────────────────────────┼───────────────┤
    │ enc_drop1 (Dropout)             │ (None, 100, 64)        │             0 │
    ├─────────────────────────────────┼────────────────────────┼───────────────┤
    │ enc_pool1 (MaxPooling1D)        │ (None, 50, 64)         │             0 │
    ├─────────────────────────────────┼────────────────────────┼───────────────┤
    │ bottleneck_conv (Conv1D)        │ (None, 50, 128)        │        24,704 │
    ├─────────────────────────────────┼────────────────────────┼───────────────┤
    │ bottleneck_drop (Dropout)       │ (None, 50, 128)        │             0 │
    ├─────────────────────────────────┼────────────────────────┼───────────────┤
    │ dec_up0 (UpSampling1D)          │ (None, 100, 128)       │             0 │
    ├─────────────────────────────────┼────────────────────────┼───────────────┤
    │ dec_conv0 (Conv1D)              │ (None, 100, 64)        │        24,640 │
    ├─────────────────────────────────┼────────────────────────┼───────────────┤
    │ dec_up1 (UpSampling1D)          │ (None, 200, 64)        │             0 │
    ├─────────────────────────────────┼────────────────────────┼───────────────┤
    │ dec_conv1 (Conv1D)              │ (None, 200, 32)        │         6,176 │
    ├─────────────────────────────────┼────────────────────────┼───────────────┤
    │ ROI (Conv1D)                    │ (None, 200, 1)         │            33 │
    └─────────────────────────────────┴────────────────────────┴───────────────┘
     Total params: 61,889 (241.75 KB)
     Trainable params: 61,889 (241.75 KB)
     Non-trainable params: 0 (0.00 B)




.. GENERATED FROM PYTHON SOURCE LINES 76-78

Train the classifier
--------------------

.. GENERATED FROM PYTHON SOURCE LINES 78-86

.. code-block:: Python

    history = dense_net.fit(
        dataset.signals,
        dataset.region_of_interest,
        validation_split=0.2,
        epochs=20,
        batch_size=64,
    )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Epoch 1/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 1s 2s/step - BinaryIoU: 0.0234 - loss: 0.6954
    Epoch 1: val_loss improved from None to 0.67507, saving model to /tmp/wavenet_ckpt_uddtyw5_/best.weights.h5

    Epoch 1: finished saving model to /tmp/wavenet_ckpt_uddtyw5_/best.weights.h5
        2/2 ━━━━━━━━━━━━━━━━━━━━ 2s 361ms/step - BinaryIoU: 0.0234 - loss: 0.6930 - val_BinaryIoU: 0.0000e+00 - val_loss: 0.6751
    Epoch 2/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 43ms/step - BinaryIoU: 0.0041 - loss: 0.6698
    Epoch 2: val_loss improved from 0.67507 to 0.64454, saving model to /tmp/wavenet_ckpt_uddtyw5_/best.weights.h5

    Epoch 2: finished saving model to /tmp/wavenet_ckpt_uddtyw5_/best.weights.h5
        2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 95ms/step - BinaryIoU: 0.0033 - loss: 0.6664 - val_BinaryIoU: 0.0000e+00 - val_loss: 0.6445
    Epoch 3/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 42ms/step - BinaryIoU: 0.0000e+00 - loss: 0.6313
    Epoch 3: val_loss improved from 0.64454 to 0.59002, saving model to /tmp/wavenet_ckpt_uddtyw5_/best.weights.h5

    Epoch 3: finished saving model to /tmp/wavenet_ckpt_uddtyw5_/best.weights.h5
        2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 92ms/step - BinaryIoU: 0.0000e+00 - loss: 0.6253 - val_BinaryIoU: 0.0000e+00 - val_loss: 0.5900
    Epoch 4/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - BinaryIoU: 0.0000e+00 - loss: 0.5659
    Epoch 4: val_loss improved from 0.59002 to 0.50336, saving model to /tmp/wavenet_ckpt_uddtyw5_/best.weights.h5

    Epoch 4: finished saving model to /tmp/wavenet_ckpt_uddtyw5_/best.weights.h5
        2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 94ms/step - BinaryIoU: 0.0000e+00 - loss: 0.5567 - val_BinaryIoU: 0.0000e+00 - val_loss: 0.5034
    Epoch 5/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 41ms/step - BinaryIoU: 0.0000e+00 - loss: 0.4639
    Epoch 5: val_loss improved from 0.50336 to 0.37699, saving model to /tmp/wavenet_ckpt_uddtyw5_/best.weights.h5

    Epoch 5: finished saving model to /tmp/wavenet_ckpt_uddtyw5_/best.weights.h5
        2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 94ms/step - BinaryIoU: 0.0000e+00 - loss: 0.4507 - val_BinaryIoU: 0.0000e+00 - val_loss: 0.3770
    Epoch 6/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 41ms/step - BinaryIoU: 0.0000e+00 - loss: 0.3236
    Epoch 6: val_loss improved from 0.37699 to 0.22661, saving model to /tmp/wavenet_ckpt_uddtyw5_/best.weights.h5

    Epoch 6: finished saving model to /tmp/wavenet_ckpt_uddtyw5_/best.weights.h5
        2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 94ms/step - BinaryIoU: 0.0000e+00 - loss: 0.3076 - val_BinaryIoU: 0.0000e+00 - val_loss: 0.2266
    Epoch 7/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 41ms/step - BinaryIoU: 0.0000e+00 - loss: 0.1767
    Epoch 7: val_loss improved from 0.22661 to 0.10983, saving model to /tmp/wavenet_ckpt_uddtyw5_/best.weights.h5

    Epoch 7: finished saving model to /tmp/wavenet_ckpt_uddtyw5_/best.weights.h5
        2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 93ms/step - BinaryIoU: 0.0000e+00 - loss: 0.1669 - val_BinaryIoU: 0.0000e+00 - val_loss: 0.1098
    Epoch 8/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 41ms/step - BinaryIoU: 0.0000e+00 - loss: 0.0930
    Epoch 8: val_loss improved from 0.10983 to 0.07153, saving model to /tmp/wavenet_ckpt_uddtyw5_/best.weights.h5

    Epoch 8: finished saving model to /tmp/wavenet_ckpt_uddtyw5_/best.weights.h5
        2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 94ms/step - BinaryIoU: 0.0000e+00 - loss: 0.0914 - val_BinaryIoU: 0.0000e+00 - val_loss: 0.0715
    Epoch 9/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 41ms/step - BinaryIoU: 0.0000e+00 - loss: 0.0935
    Epoch 9: val_loss did not improve from 0.07153
        2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - BinaryIoU: 0.0000e+00 - loss: 0.0934 - val_BinaryIoU: 0.0000e+00 - val_loss: 0.0758
    Epoch 10/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - BinaryIoU: 0.0000e+00 - loss: 0.1134
    Epoch 10: val_loss did not improve from 0.07153
        2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - BinaryIoU: 0.0000e+00 - loss: 0.1117 - val_BinaryIoU: 0.0000e+00 - val_loss: 0.0852
    Epoch 11/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - BinaryIoU: 0.0000e+00 - loss: 0.1216
    Epoch 11: val_loss did not improve from 0.07153
        2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - BinaryIoU: 0.0000e+00 - loss: 0.1290 - val_BinaryIoU: 0.0000e+00 - val_loss: 0.0892
    Epoch 12/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - BinaryIoU: 0.0000e+00 - loss: 0.1349
    Epoch 12: val_loss did not improve from 0.07153
        2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - BinaryIoU: 0.0000e+00 - loss: 0.1343 - val_BinaryIoU: 0.0000e+00 - val_loss: 0.0866
    Epoch 13/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 41ms/step - BinaryIoU: 0.0000e+00 - loss: 0.1318
    Epoch 13: val_loss did not improve from 0.07153
        2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - BinaryIoU: 0.0000e+00 - loss: 0.1289 - val_BinaryIoU: 0.0000e+00 - val_loss: 0.0797
    Epoch 14/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 41ms/step - BinaryIoU: 0.0000e+00 - loss: 0.1175
    Epoch 14: val_loss improved from 0.07153 to 0.07082, saving model to /tmp/wavenet_ckpt_uddtyw5_/best.weights.h5

    Epoch 14: finished saving model to /tmp/wavenet_ckpt_uddtyw5_/best.weights.h5
        2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 93ms/step - BinaryIoU: 0.0000e+00 - loss: 0.1179 - val_BinaryIoU: 0.0000e+00 - val_loss: 0.0708
    Epoch 15/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - BinaryIoU: 0.0000e+00 - loss: 0.1022
    Epoch 15: val_loss improved from 0.07082 to 0.06263, saving model to /tmp/wavenet_ckpt_uddtyw5_/best.weights.h5

    Epoch 15: finished saving model to /tmp/wavenet_ckpt_uddtyw5_/best.weights.h5
        2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 92ms/step - BinaryIoU: 0.0000e+00 - loss: 0.1009 - val_BinaryIoU: 0.0000e+00 - val_loss: 0.0626
    Epoch 16/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - BinaryIoU: 0.0000e+00 - loss: 0.0866
    Epoch 16: val_loss improved from 0.06263 to 0.05732, saving model to /tmp/wavenet_ckpt_uddtyw5_/best.weights.h5

    Epoch 16: finished saving model to /tmp/wavenet_ckpt_uddtyw5_/best.weights.h5
        2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 91ms/step - BinaryIoU: 0.0000e+00 - loss: 0.0863 - val_BinaryIoU: 0.0000e+00 - val_loss: 0.0573
    Epoch 17/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - BinaryIoU: 0.0000e+00 - loss: 0.0754
    Epoch 17: val_loss improved from 0.05732 to 0.05629, saving model to /tmp/wavenet_ckpt_uddtyw5_/best.weights.h5

    Epoch 17: finished saving model to /tmp/wavenet_ckpt_uddtyw5_/best.weights.h5
        2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 92ms/step - BinaryIoU: 0.0000e+00 - loss: 0.0739 - val_BinaryIoU: 0.0000e+00 - val_loss: 0.0563
    Epoch 18/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 41ms/step - BinaryIoU: 0.0000e+00 - loss: 0.0635
    Epoch 18: val_loss did not improve from 0.05629
        2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - BinaryIoU: 0.0000e+00 - loss: 0.0639 - val_BinaryIoU: 0.0000e+00 - val_loss: 0.0605
    Epoch 19/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 41ms/step - BinaryIoU: 0.0000e+00 - loss: 0.0588
    Epoch 19: val_loss did not improve from 0.05629
        2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - BinaryIoU: 0.0000e+00 - loss: 0.0594 - val_BinaryIoU: 0.0000e+00 - val_loss: 0.0689
    Epoch 20/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - BinaryIoU: 0.0000e+00 - loss: 0.0585
    Epoch 20: val_loss did not improve from 0.05629
        2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - BinaryIoU: 0.0000e+00 - loss: 0.0579 - val_BinaryIoU: 0.0000e+00 - val_loss: 0.0762
    Restored best model weights from /tmp/wavenet_ckpt_uddtyw5_/best.weights.h5




.. GENERATED FROM PYTHON SOURCE LINES 87-89

Plot training history
---------------------

.. GENERATED FROM PYTHON SOURCE LINES 89-90

.. code-block:: Python

    dense_net.plot_model_history()



.. image-sg:: /gallery/images/sphx_glr_classifier_autoencoder_002.png
   :alt: Losses, Metrics
   :srcset: /gallery/images/sphx_glr_classifier_autoencoder_002.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    <Figure size 900x720 with 2 Axes>




.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 8.441 seconds)


.. _sphx_glr_download_gallery_classifier_autoencoder.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: classifier_autoencoder.ipynb <classifier_autoencoder.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: classifier_autoencoder.py <classifier_autoencoder.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: classifier_autoencoder.zip <classifier_autoencoder.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
