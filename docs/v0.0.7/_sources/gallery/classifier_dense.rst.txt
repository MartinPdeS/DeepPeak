
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "gallery/classifier_dense.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_gallery_classifier_dense.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_gallery_classifier_dense.py:


DenseNet Classifier: Detecting Regions of Interest in Synthetic Signals
=======================================================================

This example demonstrates how to use DeepPeak's DenseNet classifier to identify
regions of interest (ROIs) in synthetic 1D signals containing Gaussian peaks.

We will:
- Generate a dataset of noisy signals with random Gaussian peaks
- Build and train a DenseNet classifier to detect ROIs
- Visualize the training process and model predictions

.. note::
    This example is fully reproducible and suitable for Sphinx-Gallery documentation.

.. GENERATED FROM PYTHON SOURCE LINES 19-21

Imports and reproducibility
--------------------------

.. GENERATED FROM PYTHON SOURCE LINES 21-29

.. code-block:: Python

    import numpy as np

    from DeepPeak.machine_learning.classifier import DenseNet
    from DeepPeak.signals import SignalDatasetGenerator
    from DeepPeak import kernel

    np.random.seed(42)








.. GENERATED FROM PYTHON SOURCE LINES 30-32

Generate synthetic dataset
-------------------------

.. GENERATED FROM PYTHON SOURCE LINES 32-53

.. code-block:: Python

    NUM_PEAKS = 3
    SEQUENCE_LENGTH = 200

    kernel = kernel.Lorentzian(
        amplitude=(10, 30),
        position=(0, SEQUENCE_LENGTH),
        width=(3, 6),
    )

    generator = SignalDatasetGenerator(sequence_length=SEQUENCE_LENGTH)

    dataset = generator.generate(
        n_samples=300,
        kernel=kernel,
        n_peaks=(1, NUM_PEAKS),
        noise_std=0.1,
        categorical_peak_count=False,
    )

    dataset.compute_region_of_interest(width_in_pixels=5)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    DataSet(signals, amplitudes, positions, widths, labels, x_values, num_peaks)



.. GENERATED FROM PYTHON SOURCE LINES 54-56

Visualize a few example signals and their regions of interest
------------------------------------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 56-58

.. code-block:: Python

    dataset.plot(number_of_samples=3)




.. image-sg:: /gallery/images/sphx_glr_classifier_dense_001.png
   :alt: Sample 0, Sample 1, Sample 2
   :srcset: /gallery/images/sphx_glr_classifier_dense_001.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    <Figure size 800x900 with 3 Axes>



.. GENERATED FROM PYTHON SOURCE LINES 59-61

Build and summarize the DenseNet classifier
------------------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 61-73

.. code-block:: Python

    dense_net = DenseNet(
        sequence_length=SEQUENCE_LENGTH,
        filters=(32, 64, 128),
        dilation_rates=(1, 2, 4),
        kernel_size=3,
        optimizer="adam",
        loss="binary_crossentropy",
        metrics=["accuracy"],
    )
    dense_net.build()
    dense_net.summary()





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Model: "DenseNetDetector"
    ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
    ┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
    ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
    │ input (InputLayer)              │ (None, 200, 1)         │             0 │
    ├─────────────────────────────────┼────────────────────────┼───────────────┤
    │ conv_0 (Conv1D)                 │ (None, 200, 32)        │           128 │
    ├─────────────────────────────────┼────────────────────────┼───────────────┤
    │ conv_1 (Conv1D)                 │ (None, 200, 64)        │         6,208 │
    ├─────────────────────────────────┼────────────────────────┼───────────────┤
    │ conv_2 (Conv1D)                 │ (None, 200, 128)       │        24,704 │
    ├─────────────────────────────────┼────────────────────────┼───────────────┤
    │ ROI (Conv1D)                    │ (None, 200, 1)         │           129 │
    └─────────────────────────────────┴────────────────────────┴───────────────┘
     Total params: 31,169 (121.75 KB)
     Trainable params: 31,169 (121.75 KB)
     Non-trainable params: 0 (0.00 B)




.. GENERATED FROM PYTHON SOURCE LINES 74-76

Train the classifier
--------------------

.. GENERATED FROM PYTHON SOURCE LINES 76-84

.. code-block:: Python

    history = dense_net.fit(
        dataset.signals,
        dataset.region_of_interest,
        validation_split=0.2,
        epochs=20,
        batch_size=64,
    )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Epoch 1/20
    1/4 ━━━━━━━━━━━━━━━━━━━━ 3s 1s/step - accuracy: 0.0497 - loss: 0.9588    4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 23ms/step - accuracy: 0.2882 - loss: 0.8451
    Epoch 1: val_loss improved from None to 0.63081, saving model to /tmp/wavenet_ckpt_hknvbjo8/best.weights.h5

    Epoch 1: finished saving model to /tmp/wavenet_ckpt_hknvbjo8/best.weights.h5
        4/4 ━━━━━━━━━━━━━━━━━━━━ 1s 97ms/step - accuracy: 0.5219 - loss: 0.7625 - val_accuracy: 0.9502 - val_loss: 0.6308
    Epoch 2/20
    1/4 ━━━━━━━━━━━━━━━━━━━━ 0s 36ms/step - accuracy: 0.9459 - loss: 0.6299    4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step - accuracy: 0.9489 - loss: 0.6299
    Epoch 2: val_loss improved from 0.63081 to 0.58940, saving model to /tmp/wavenet_ckpt_hknvbjo8/best.weights.h5

    Epoch 2: finished saving model to /tmp/wavenet_ckpt_hknvbjo8/best.weights.h5
        4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 44ms/step - accuracy: 0.9502 - loss: 0.6272 - val_accuracy: 0.9502 - val_loss: 0.5894
    Epoch 3/20
    1/4 ━━━━━━━━━━━━━━━━━━━━ 0s 38ms/step - accuracy: 0.9514 - loss: 0.5832    4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step - accuracy: 0.9502 - loss: 0.5732
    Epoch 3: val_loss improved from 0.58940 to 0.50259, saving model to /tmp/wavenet_ckpt_hknvbjo8/best.weights.h5

    Epoch 3: finished saving model to /tmp/wavenet_ckpt_hknvbjo8/best.weights.h5
        4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 43ms/step - accuracy: 0.9504 - loss: 0.5622 - val_accuracy: 0.9587 - val_loss: 0.5026
    Epoch 4/20
    1/4 ━━━━━━━━━━━━━━━━━━━━ 0s 38ms/step - accuracy: 0.9563 - loss: 0.5048    4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step - accuracy: 0.9672 - loss: 0.4942
    Epoch 4: val_loss improved from 0.50259 to 0.43656, saving model to /tmp/wavenet_ckpt_hknvbjo8/best.weights.h5

    Epoch 4: finished saving model to /tmp/wavenet_ckpt_hknvbjo8/best.weights.h5
        4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 43ms/step - accuracy: 0.9756 - loss: 0.4852 - val_accuracy: 0.9893 - val_loss: 0.4366
    Epoch 5/20
    1/4 ━━━━━━━━━━━━━━━━━━━━ 0s 36ms/step - accuracy: 0.9871 - loss: 0.4385    4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step - accuracy: 0.9857 - loss: 0.4302
    Epoch 5: val_loss improved from 0.43656 to 0.37067, saving model to /tmp/wavenet_ckpt_hknvbjo8/best.weights.h5

    Epoch 5: finished saving model to /tmp/wavenet_ckpt_hknvbjo8/best.weights.h5
        4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 44ms/step - accuracy: 0.9859 - loss: 0.4199 - val_accuracy: 0.9883 - val_loss: 0.3707
    Epoch 6/20
    1/4 ━━━━━━━━━━━━━━━━━━━━ 0s 37ms/step - accuracy: 0.9859 - loss: 0.3809    4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step - accuracy: 0.9883 - loss: 0.3677
    Epoch 6: val_loss improved from 0.37067 to 0.30344, saving model to /tmp/wavenet_ckpt_hknvbjo8/best.weights.h5

    Epoch 6: finished saving model to /tmp/wavenet_ckpt_hknvbjo8/best.weights.h5
        4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 44ms/step - accuracy: 0.9897 - loss: 0.3547 - val_accuracy: 0.9934 - val_loss: 0.3034
    Epoch 7/20
    1/4 ━━━━━━━━━━━━━━━━━━━━ 0s 37ms/step - accuracy: 0.9910 - loss: 0.3147    4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step - accuracy: 0.9914 - loss: 0.2988
    Epoch 7: val_loss improved from 0.30344 to 0.23409, saving model to /tmp/wavenet_ckpt_hknvbjo8/best.weights.h5

    Epoch 7: finished saving model to /tmp/wavenet_ckpt_hknvbjo8/best.weights.h5
        4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 43ms/step - accuracy: 0.9910 - loss: 0.2866 - val_accuracy: 0.9934 - val_loss: 0.2341
    Epoch 8/20
    1/4 ━━━━━━━━━━━━━━━━━━━━ 0s 36ms/step - accuracy: 0.9913 - loss: 0.2267    4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step - accuracy: 0.9915 - loss: 0.2207
    Epoch 8: val_loss improved from 0.23409 to 0.16613, saving model to /tmp/wavenet_ckpt_hknvbjo8/best.weights.h5

    Epoch 8: finished saving model to /tmp/wavenet_ckpt_hknvbjo8/best.weights.h5
        4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 43ms/step - accuracy: 0.9912 - loss: 0.2154 - val_accuracy: 0.9927 - val_loss: 0.1661
    Epoch 9/20
    1/4 ━━━━━━━━━━━━━━━━━━━━ 0s 36ms/step - accuracy: 0.9922 - loss: 0.1650    4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step - accuracy: 0.9915 - loss: 0.1577
    Epoch 9: val_loss improved from 0.16613 to 0.10565, saving model to /tmp/wavenet_ckpt_hknvbjo8/best.weights.h5

    Epoch 9: finished saving model to /tmp/wavenet_ckpt_hknvbjo8/best.weights.h5
        4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 44ms/step - accuracy: 0.9915 - loss: 0.1484 - val_accuracy: 0.9941 - val_loss: 0.1056
    Epoch 10/20
    1/4 ━━━━━━━━━━━━━━━━━━━━ 0s 38ms/step - accuracy: 0.9948 - loss: 0.1053    4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 23ms/step - accuracy: 0.9924 - loss: 0.1020
    Epoch 10: val_loss improved from 0.10565 to 0.07115, saving model to /tmp/wavenet_ckpt_hknvbjo8/best.weights.h5

    Epoch 10: finished saving model to /tmp/wavenet_ckpt_hknvbjo8/best.weights.h5
        4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 44ms/step - accuracy: 0.9913 - loss: 0.0959 - val_accuracy: 0.9902 - val_loss: 0.0712
    Epoch 11/20
    1/4 ━━━━━━━━━━━━━━━━━━━━ 0s 37ms/step - accuracy: 0.9907 - loss: 0.0675    4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step - accuracy: 0.9912 - loss: 0.0638
    Epoch 11: val_loss improved from 0.07115 to 0.04440, saving model to /tmp/wavenet_ckpt_hknvbjo8/best.weights.h5

    Epoch 11: finished saving model to /tmp/wavenet_ckpt_hknvbjo8/best.weights.h5
        4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 44ms/step - accuracy: 0.9916 - loss: 0.0609 - val_accuracy: 0.9926 - val_loss: 0.0444
    Epoch 12/20
    1/4 ━━━━━━━━━━━━━━━━━━━━ 0s 37ms/step - accuracy: 0.9914 - loss: 0.0436    4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step - accuracy: 0.9911 - loss: 0.0432
    Epoch 12: val_loss improved from 0.04440 to 0.03489, saving model to /tmp/wavenet_ckpt_hknvbjo8/best.weights.h5

    Epoch 12: finished saving model to /tmp/wavenet_ckpt_hknvbjo8/best.weights.h5
        4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 44ms/step - accuracy: 0.9915 - loss: 0.0409 - val_accuracy: 0.9938 - val_loss: 0.0349
    Epoch 13/20
    1/4 ━━━━━━━━━━━━━━━━━━━━ 0s 37ms/step - accuracy: 0.9920 - loss: 0.0400    4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step - accuracy: 0.9923 - loss: 0.0354
    Epoch 13: val_loss improved from 0.03489 to 0.02939, saving model to /tmp/wavenet_ckpt_hknvbjo8/best.weights.h5

    Epoch 13: finished saving model to /tmp/wavenet_ckpt_hknvbjo8/best.weights.h5
        4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 44ms/step - accuracy: 0.9925 - loss: 0.0318 - val_accuracy: 0.9919 - val_loss: 0.0294
    Epoch 14/20
    1/4 ━━━━━━━━━━━━━━━━━━━━ 0s 38ms/step - accuracy: 0.9927 - loss: 0.0240    4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 23ms/step - accuracy: 0.9923 - loss: 0.0262
    Epoch 14: val_loss improved from 0.02939 to 0.02578, saving model to /tmp/wavenet_ckpt_hknvbjo8/best.weights.h5

    Epoch 14: finished saving model to /tmp/wavenet_ckpt_hknvbjo8/best.weights.h5
        4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 45ms/step - accuracy: 0.9921 - loss: 0.0269 - val_accuracy: 0.9928 - val_loss: 0.0258
    Epoch 15/20
    1/4 ━━━━━━━━━━━━━━━━━━━━ 0s 39ms/step - accuracy: 0.9923 - loss: 0.0241    4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step - accuracy: 0.9925 - loss: 0.0238
    Epoch 15: val_loss improved from 0.02578 to 0.02449, saving model to /tmp/wavenet_ckpt_hknvbjo8/best.weights.h5

    Epoch 15: finished saving model to /tmp/wavenet_ckpt_hknvbjo8/best.weights.h5
        4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 44ms/step - accuracy: 0.9926 - loss: 0.0236 - val_accuracy: 0.9938 - val_loss: 0.0245
    Epoch 16/20
    1/4 ━━━━━━━━━━━━━━━━━━━━ 0s 39ms/step - accuracy: 0.9939 - loss: 0.0202    3/4 ━━━━━━━━━━━━━━━━━━━━ 0s 27ms/step - accuracy: 0.9933 - loss: 0.0217
    Epoch 16: val_loss improved from 0.02449 to 0.02260, saving model to /tmp/wavenet_ckpt_hknvbjo8/best.weights.h5

    Epoch 16: finished saving model to /tmp/wavenet_ckpt_hknvbjo8/best.weights.h5
        4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 46ms/step - accuracy: 0.9929 - loss: 0.0221 - val_accuracy: 0.9934 - val_loss: 0.0226
    Epoch 17/20
    1/4 ━━━━━━━━━━━━━━━━━━━━ 0s 38ms/step - accuracy: 0.9934 - loss: 0.0176    4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 23ms/step - accuracy: 0.9929 - loss: 0.0200
    Epoch 17: val_loss did not improve from 0.02260
        4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 38ms/step - accuracy: 0.9929 - loss: 0.0208 - val_accuracy: 0.9925 - val_loss: 0.0234
    Epoch 18/20
    1/4 ━━━━━━━━━━━━━━━━━━━━ 0s 38ms/step - accuracy: 0.9925 - loss: 0.0214    4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 23ms/step - accuracy: 0.9928 - loss: 0.0213
    Epoch 18: val_loss did not improve from 0.02260
        4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 39ms/step - accuracy: 0.9933 - loss: 0.0201 - val_accuracy: 0.9938 - val_loss: 0.0230
    Epoch 19/20
    1/4 ━━━━━━━━━━━━━━━━━━━━ 0s 36ms/step - accuracy: 0.9925 - loss: 0.0210    4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step - accuracy: 0.9928 - loss: 0.0203
    Epoch 19: val_loss improved from 0.02260 to 0.02086, saving model to /tmp/wavenet_ckpt_hknvbjo8/best.weights.h5

    Epoch 19: finished saving model to /tmp/wavenet_ckpt_hknvbjo8/best.weights.h5
        4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 44ms/step - accuracy: 0.9929 - loss: 0.0198 - val_accuracy: 0.9933 - val_loss: 0.0209
    Epoch 20/20
    1/4 ━━━━━━━━━━━━━━━━━━━━ 0s 37ms/step - accuracy: 0.9943 - loss: 0.0155    4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step - accuracy: 0.9936 - loss: 0.0187
    Epoch 20: val_loss improved from 0.02086 to 0.02081, saving model to /tmp/wavenet_ckpt_hknvbjo8/best.weights.h5

    Epoch 20: finished saving model to /tmp/wavenet_ckpt_hknvbjo8/best.weights.h5
        4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 43ms/step - accuracy: 0.9935 - loss: 0.0193 - val_accuracy: 0.9930 - val_loss: 0.0208
    Restored best model weights from /tmp/wavenet_ckpt_hknvbjo8/best.weights.h5




.. GENERATED FROM PYTHON SOURCE LINES 85-87

Plot training history
---------------------

.. GENERATED FROM PYTHON SOURCE LINES 87-88

.. code-block:: Python

    dense_net.plot_model_history()



.. image-sg:: /gallery/images/sphx_glr_classifier_dense_002.png
   :alt: Losses, Metrics
   :srcset: /gallery/images/sphx_glr_classifier_dense_002.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    <Figure size 900x720 with 2 Axes>




.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 5.462 seconds)


.. _sphx_glr_download_gallery_classifier_dense.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: classifier_dense.ipynb <classifier_dense.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: classifier_dense.py <classifier_dense.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: classifier_dense.zip <classifier_dense.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
