
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "gallery/classifier_wavenet.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_gallery_classifier_wavenet.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_gallery_classifier_wavenet.py:


DenseNet Classifier: Detecting Regions of Interest in Synthetic Signals
======================================================================

This example demonstrates how to use DeepPeak's DenseNet classifier to identify
regions of interest (ROIs) in synthetic 1D signals containing Gaussian peaks.

We will:
- Generate a dataset of noisy signals with random Gaussian peaks
- Build and train a DenseNet classifier to detect ROIs
- Visualize the training process and model predictions

.. note::
    This example is fully reproducible and suitable for Sphinx-Gallery documentation.

.. GENERATED FROM PYTHON SOURCE LINES 19-21

Imports and reproducibility
--------------------------

.. GENERATED FROM PYTHON SOURCE LINES 21-28

.. code-block:: Python

    import numpy as np
    import matplotlib.pyplot as plt
    from DeepPeak.signals import SignalDatasetGenerator, Kernel
    from DeepPeak.machine_learning.classifier import WaveNet

    np.random.seed(42)








.. GENERATED FROM PYTHON SOURCE LINES 29-31

Generate synthetic dataset
-------------------------

.. GENERATED FROM PYTHON SOURCE LINES 31-50

.. code-block:: Python

    NUM_PEAKS = 3
    SEQUENCE_LENGTH = 200

    generator = SignalDatasetGenerator(
        n_samples=100,
        sequence_length=SEQUENCE_LENGTH
    )

    dataset = generator.generate(
        signal_type=Kernel.GAUSSIAN,
        n_peaks=(1, NUM_PEAKS),
        amplitude=(1, 20),
        position=(0.1, 0.9),
        width=(0.03, 0.05),
        noise_std=0.1,
        categorical_peak_count=False,
        compute_region_of_interest=True
    )








.. GENERATED FROM PYTHON SOURCE LINES 51-53

Visualize a few example signals and their regions of interest
------------------------------------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 53-55

.. code-block:: Python

    dataset.plot(number_of_samples=3)




.. image-sg:: /gallery/images/sphx_glr_classifier_wavenet_001.png
   :alt: classifier wavenet
   :srcset: /gallery/images/sphx_glr_classifier_wavenet_001.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 56-58

Build and summarize the WaveNet classifier
------------------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 58-70

.. code-block:: Python

    dense_net = WaveNet(
        sequence_length=SEQUENCE_LENGTH,
        num_filters=64,
        num_dilation_layers=6,
        kernel_size=3,
        optimizer='adam',
        loss='binary_crossentropy',
        metrics=['accuracy']
    )
    dense_net.build()
    dense_net.summary()





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Model: "WaveNetDetector"
    ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
    ┃ Layer (type)                  ┃ Output Shape              ┃         Param # ┃ Connected to               ┃
    ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
    │ input (InputLayer)            │ (None, 200, 1)            │               0 │ -                          │
    ├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
    │ input_projection (Conv1D)     │ (None, 200, 64)           │             128 │ input[0][0]                │
    ├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
    │ dilated_conv_0 (Conv1D)       │ (None, 200, 64)           │          12,352 │ input_projection[0][0]     │
    ├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
    │ res_0 (Conv1D)                │ (None, 200, 64)           │           4,160 │ dilated_conv_0[0][0]       │
    ├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
    │ residual_add_0 (Add)          │ (None, 200, 64)           │               0 │ input_projection[0][0],    │
    │                               │                           │                 │ res_0[0][0]                │
    ├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
    │ dilated_conv_1 (Conv1D)       │ (None, 200, 64)           │          12,352 │ residual_add_0[0][0]       │
    ├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
    │ res_1 (Conv1D)                │ (None, 200, 64)           │           4,160 │ dilated_conv_1[0][0]       │
    ├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
    │ residual_add_1 (Add)          │ (None, 200, 64)           │               0 │ residual_add_0[0][0],      │
    │                               │                           │                 │ res_1[0][0]                │
    ├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
    │ dilated_conv_2 (Conv1D)       │ (None, 200, 64)           │          12,352 │ residual_add_1[0][0]       │
    ├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
    │ res_2 (Conv1D)                │ (None, 200, 64)           │           4,160 │ dilated_conv_2[0][0]       │
    ├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
    │ residual_add_2 (Add)          │ (None, 200, 64)           │               0 │ residual_add_1[0][0],      │
    │                               │                           │                 │ res_2[0][0]                │
    ├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
    │ dilated_conv_3 (Conv1D)       │ (None, 200, 64)           │          12,352 │ residual_add_2[0][0]       │
    ├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
    │ res_3 (Conv1D)                │ (None, 200, 64)           │           4,160 │ dilated_conv_3[0][0]       │
    ├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
    │ residual_add_3 (Add)          │ (None, 200, 64)           │               0 │ residual_add_2[0][0],      │
    │                               │                           │                 │ res_3[0][0]                │
    ├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
    │ dilated_conv_4 (Conv1D)       │ (None, 200, 64)           │          12,352 │ residual_add_3[0][0]       │
    ├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
    │ res_4 (Conv1D)                │ (None, 200, 64)           │           4,160 │ dilated_conv_4[0][0]       │
    ├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
    │ residual_add_4 (Add)          │ (None, 200, 64)           │               0 │ residual_add_3[0][0],      │
    │                               │                           │                 │ res_4[0][0]                │
    ├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
    │ dilated_conv_5 (Conv1D)       │ (None, 200, 64)           │          12,352 │ residual_add_4[0][0]       │
    ├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
    │ res_5 (Conv1D)                │ (None, 200, 64)           │           4,160 │ dilated_conv_5[0][0]       │
    ├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
    │ residual_add_5 (Add)          │ (None, 200, 64)           │               0 │ residual_add_4[0][0],      │
    │                               │                           │                 │ res_5[0][0]                │
    ├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
    │ skip_0 (Conv1D)               │ (None, 200, 64)           │           4,160 │ residual_add_0[0][0]       │
    ├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
    │ skip_1 (Conv1D)               │ (None, 200, 64)           │           4,160 │ residual_add_1[0][0]       │
    ├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
    │ skip_2 (Conv1D)               │ (None, 200, 64)           │           4,160 │ residual_add_2[0][0]       │
    ├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
    │ skip_3 (Conv1D)               │ (None, 200, 64)           │           4,160 │ residual_add_3[0][0]       │
    ├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
    │ skip_4 (Conv1D)               │ (None, 200, 64)           │           4,160 │ residual_add_4[0][0]       │
    ├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
    │ skip_5 (Conv1D)               │ (None, 200, 64)           │           4,160 │ residual_add_5[0][0]       │
    ├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
    │ skip_add (Add)                │ (None, 200, 64)           │               0 │ skip_0[0][0],              │
    │                               │                           │                 │ skip_1[0][0],              │
    │                               │                           │                 │ skip_2[0][0],              │
    │                               │                           │                 │ skip_3[0][0],              │
    │                               │                           │                 │ skip_4[0][0], skip_5[0][0] │
    ├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
    │ post_relu (ReLU)              │ (None, 200, 64)           │               0 │ skip_add[0][0]             │
    ├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
    │ output (Conv1D)               │ (None, 200, 1)            │              65 │ post_relu[0][0]            │
    └───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘
     Total params: 124,225 (485.25 KB)
     Trainable params: 124,225 (485.25 KB)
     Non-trainable params: 0 (0.00 B)




.. GENERATED FROM PYTHON SOURCE LINES 71-73

Train the classifier
--------------------

.. GENERATED FROM PYTHON SOURCE LINES 73-81

.. code-block:: Python

    history = dense_net.fit(
        dataset.signals,
        dataset.region_of_interest,
        validation_split=0.2,
        epochs=20,
        batch_size=64
    )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Epoch 1/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 2s 3s/step - accuracy: 0.0515 - loss: 3.1677    2/2 ━━━━━━━━━━━━━━━━━━━━ 3s 284ms/step - accuracy: 0.1439 - loss: 2.8511 - val_accuracy: 0.9283 - val_loss: 0.6018
    Epoch 2/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 90ms/step - accuracy: 0.8999 - loss: 0.7039    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.9059 - loss: 0.6690 - val_accuracy: 0.9150 - val_loss: 0.4877
    Epoch 3/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 241ms/step - accuracy: 0.8906 - loss: 0.5435    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.8973 - loss: 0.5187 - val_accuracy: 0.9612 - val_loss: 0.2919
    Epoch 4/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 83ms/step - accuracy: 0.9480 - loss: 0.3353    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.9491 - loss: 0.3347 - val_accuracy: 0.9612 - val_loss: 0.2491
    Epoch 5/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 81ms/step - accuracy: 0.9499 - loss: 0.3215    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.9507 - loss: 0.3075 - val_accuracy: 0.9625 - val_loss: 0.1798
    Epoch 6/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 85ms/step - accuracy: 0.9453 - loss: 0.2311    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.9448 - loss: 0.2276 - val_accuracy: 0.9623 - val_loss: 0.1469
    Epoch 7/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 83ms/step - accuracy: 0.9452 - loss: 0.1953    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.9460 - loss: 0.1924 - val_accuracy: 0.9620 - val_loss: 0.1223
    Epoch 8/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 84ms/step - accuracy: 0.9502 - loss: 0.1627    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.9509 - loss: 0.1627 - val_accuracy: 0.9710 - val_loss: 0.0919
    Epoch 9/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 89ms/step - accuracy: 0.9577 - loss: 0.1239    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.9569 - loss: 0.1232 - val_accuracy: 0.9647 - val_loss: 0.0906
    Epoch 10/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 89ms/step - accuracy: 0.9516 - loss: 0.1177    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.9525 - loss: 0.1171 - val_accuracy: 0.9645 - val_loss: 0.0855
    Epoch 11/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 84ms/step - accuracy: 0.9584 - loss: 0.1056    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 76ms/step - accuracy: 0.9564 - loss: 0.1066 - val_accuracy: 0.9655 - val_loss: 0.0840
    Epoch 12/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 101ms/step - accuracy: 0.9556 - loss: 0.1004    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 104ms/step - accuracy: 0.9554 - loss: 0.1016 - val_accuracy: 0.9688 - val_loss: 0.0859
    Epoch 13/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 108ms/step - accuracy: 0.9527 - loss: 0.1095    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 91ms/step - accuracy: 0.9543 - loss: 0.1064 - val_accuracy: 0.9658 - val_loss: 0.0826
    Epoch 14/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 99ms/step - accuracy: 0.9563 - loss: 0.1014    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 81ms/step - accuracy: 0.9569 - loss: 0.0990 - val_accuracy: 0.9635 - val_loss: 0.0843
    Epoch 15/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 102ms/step - accuracy: 0.9514 - loss: 0.1017    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 85ms/step - accuracy: 0.9524 - loss: 0.1006 - val_accuracy: 0.9712 - val_loss: 0.0784
    Epoch 16/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 111ms/step - accuracy: 0.9601 - loss: 0.0959    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 92ms/step - accuracy: 0.9595 - loss: 0.0957 - val_accuracy: 0.9720 - val_loss: 0.0733
    Epoch 17/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 101ms/step - accuracy: 0.9621 - loss: 0.0912    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 82ms/step - accuracy: 0.9620 - loss: 0.0901 - val_accuracy: 0.9647 - val_loss: 0.0734
    Epoch 18/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 104ms/step - accuracy: 0.9556 - loss: 0.0911    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.9563 - loss: 0.0923 - val_accuracy: 0.9743 - val_loss: 0.0683
    Epoch 19/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 109ms/step - accuracy: 0.9645 - loss: 0.0873    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 91ms/step - accuracy: 0.9642 - loss: 0.0868 - val_accuracy: 0.9743 - val_loss: 0.0690
    Epoch 20/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 110ms/step - accuracy: 0.9627 - loss: 0.0875    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 94ms/step - accuracy: 0.9628 - loss: 0.0869 - val_accuracy: 0.9693 - val_loss: 0.0659




.. GENERATED FROM PYTHON SOURCE LINES 82-84

Plot training history
---------------------

.. GENERATED FROM PYTHON SOURCE LINES 84-86

.. code-block:: Python

    dense_net.plot_model_history(history)




.. image-sg:: /gallery/images/sphx_glr_classifier_wavenet_002.png
   :alt: Loss, Accuracy
   :srcset: /gallery/images/sphx_glr_classifier_wavenet_002.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 87-89

Predict and visualize on a test signal
--------------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 89-92

.. code-block:: Python

    dense_net.plot_prediction(
        signal=dataset.signals[0:1, :],
        threshold=0.4
    )


.. image-sg:: /gallery/images/sphx_glr_classifier_wavenet_003.png
   :alt: Predicted Region of Interest
   :srcset: /gallery/images/sphx_glr_classifier_wavenet_003.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    <Figure size 1200x500 with 1 Axes>




.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 7.549 seconds)


.. _sphx_glr_download_gallery_classifier_wavenet.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: classifier_wavenet.ipynb <classifier_wavenet.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: classifier_wavenet.py <classifier_wavenet.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: classifier_wavenet.zip <classifier_wavenet.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
