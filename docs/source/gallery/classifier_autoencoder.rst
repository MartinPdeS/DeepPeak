
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "gallery/classifier_autoencoder.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_gallery_classifier_autoencoder.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_gallery_classifier_autoencoder.py:


DenseNet Classifier: Detecting Regions of Interest in Synthetic Signals
======================================================================

This example demonstrates how to use DeepPeak's DenseNet classifier to identify
regions of interest (ROIs) in synthetic 1D signals containing Gaussian peaks.

We will:
- Generate a dataset of noisy signals with random Gaussian peaks
- Build and train a DenseNet classifier to detect ROIs
- Visualize the training process and model predictions

.. note::
    This example is fully reproducible and suitable for Sphinx-Gallery documentation.

.. GENERATED FROM PYTHON SOURCE LINES 19-21

Imports and reproducibility
--------------------------

.. GENERATED FROM PYTHON SOURCE LINES 21-28

.. code-block:: Python

    import numpy as np
    import matplotlib.pyplot as plt
    from DeepPeak.signals import SignalDatasetGenerator, Kernel
    from DeepPeak.machine_learning.classifier import Autoencoder

    np.random.seed(42)








.. GENERATED FROM PYTHON SOURCE LINES 29-31

Generate synthetic dataset
-------------------------

.. GENERATED FROM PYTHON SOURCE LINES 31-50

.. code-block:: Python

    NUM_PEAKS = 3
    SEQUENCE_LENGTH = 200

    generator = SignalDatasetGenerator(
        n_samples=100,
        sequence_length=SEQUENCE_LENGTH
    )

    dataset = generator.generate(
        signal_type=Kernel.GAUSSIAN,
        n_peaks=(1, NUM_PEAKS),
        amplitude=(1, 20),
        position=(0.1, 0.9),
        width=(0.03, 0.05),
        noise_std=0.1,
        categorical_peak_count=False,
        compute_region_of_interest=True
    )








.. GENERATED FROM PYTHON SOURCE LINES 51-53

Visualize a few example signals and their regions of interest
------------------------------------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 53-55

.. code-block:: Python

    dataset.plot(number_of_samples=3)




.. image-sg:: /gallery/images/sphx_glr_classifier_autoencoder_001.png
   :alt: classifier autoencoder
   :srcset: /gallery/images/sphx_glr_classifier_autoencoder_001.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 56-58

Build and summarize the WaveNet classifier
------------------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 58-72

.. code-block:: Python

    dense_net = Autoencoder(
        sequence_length=SEQUENCE_LENGTH,
        dropout_rate=0.30,
        filters=(32, 64, 128),
        kernel_size=3,
        pool_size=2,
        upsample_size=2,
        optimizer='adam',
        loss='binary_crossentropy',
        metrics=['accuracy']
    )
    dense_net.build()
    dense_net.summary()





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Model: "AutoencoderROILocator"
    ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓
    ┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃
    ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩
    │ input (InputLayer)                   │ (None, 200, 1)              │               0 │
    ├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
    │ enc_conv0 (Conv1D)                   │ (None, 200, 32)             │             128 │
    ├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
    │ enc_drop0 (Dropout)                  │ (None, 200, 32)             │               0 │
    ├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
    │ enc_pool0 (MaxPooling1D)             │ (None, 100, 32)             │               0 │
    ├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
    │ enc_conv1 (Conv1D)                   │ (None, 100, 64)             │           6,208 │
    ├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
    │ enc_drop1 (Dropout)                  │ (None, 100, 64)             │               0 │
    ├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
    │ enc_pool1 (MaxPooling1D)             │ (None, 50, 64)              │               0 │
    ├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
    │ bottleneck_conv (Conv1D)             │ (None, 50, 128)             │          24,704 │
    ├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
    │ bottleneck_drop (Dropout)            │ (None, 50, 128)             │               0 │
    ├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
    │ dec_up0 (UpSampling1D)               │ (None, 100, 128)            │               0 │
    ├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
    │ dec_conv0 (Conv1D)                   │ (None, 100, 64)             │          24,640 │
    ├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
    │ dec_up1 (UpSampling1D)               │ (None, 200, 64)             │               0 │
    ├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
    │ dec_conv1 (Conv1D)                   │ (None, 200, 32)             │           6,176 │
    ├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
    │ ROI (Conv1D)                         │ (None, 200, 1)              │              33 │
    └──────────────────────────────────────┴─────────────────────────────┴─────────────────┘
     Total params: 61,889 (241.75 KB)
     Trainable params: 61,889 (241.75 KB)
     Non-trainable params: 0 (0.00 B)




.. GENERATED FROM PYTHON SOURCE LINES 73-75

Train the classifier
--------------------

.. GENERATED FROM PYTHON SOURCE LINES 75-83

.. code-block:: Python

    history = dense_net.fit(
        dataset.signals,
        dataset.region_of_interest,
        validation_split=0.2,
        epochs=20,
        batch_size=64
    )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Epoch 1/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step - accuracy: 0.2179 - loss: 0.7482    2/2 ━━━━━━━━━━━━━━━━━━━━ 1s 170ms/step - accuracy: 0.3142 - loss: 0.7363 - val_accuracy: 0.9612 - val_loss: 0.6475
    Epoch 2/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 27ms/step - accuracy: 0.9484 - loss: 0.6578    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 38ms/step - accuracy: 0.9492 - loss: 0.6545 - val_accuracy: 0.9612 - val_loss: 0.6270
    Epoch 3/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 26ms/step - accuracy: 0.9484 - loss: 0.6172    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 34ms/step - accuracy: 0.9492 - loss: 0.6172 - val_accuracy: 0.9612 - val_loss: 0.6067
    Epoch 4/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 28ms/step - accuracy: 0.9516 - loss: 0.5793    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 35ms/step - accuracy: 0.9503 - loss: 0.5774 - val_accuracy: 0.9612 - val_loss: 0.5784
    Epoch 5/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 25ms/step - accuracy: 0.9496 - loss: 0.5328    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 34ms/step - accuracy: 0.9497 - loss: 0.5291 - val_accuracy: 0.9663 - val_loss: 0.5266
    Epoch 6/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 25ms/step - accuracy: 0.9499 - loss: 0.4706    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 34ms/step - accuracy: 0.9504 - loss: 0.4665 - val_accuracy: 0.9747 - val_loss: 0.4496
    Epoch 7/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 26ms/step - accuracy: 0.9494 - loss: 0.3950    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 34ms/step - accuracy: 0.9504 - loss: 0.3879 - val_accuracy: 0.9683 - val_loss: 0.3597
    Epoch 8/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 26ms/step - accuracy: 0.9508 - loss: 0.3103    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 34ms/step - accuracy: 0.9513 - loss: 0.3005 - val_accuracy: 0.9480 - val_loss: 0.2784
    Epoch 9/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 26ms/step - accuracy: 0.9534 - loss: 0.2163    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 34ms/step - accuracy: 0.9533 - loss: 0.2122 - val_accuracy: 0.9342 - val_loss: 0.2067
    Epoch 10/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 32ms/step - accuracy: 0.9497 - loss: 0.1649    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 46ms/step - accuracy: 0.9501 - loss: 0.1597 - val_accuracy: 0.9370 - val_loss: 0.1488
    Epoch 11/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 38ms/step - accuracy: 0.9534 - loss: 0.1174    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.9523 - loss: 0.1173 - val_accuracy: 0.9532 - val_loss: 0.1122
    Epoch 12/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 37ms/step - accuracy: 0.9561 - loss: 0.1193    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.9554 - loss: 0.1201 - val_accuracy: 0.9497 - val_loss: 0.1094
    Epoch 13/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 42ms/step - accuracy: 0.9551 - loss: 0.0974    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 59ms/step - accuracy: 0.9548 - loss: 0.0977 - val_accuracy: 0.9523 - val_loss: 0.1092
    Epoch 14/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 35ms/step - accuracy: 0.9532 - loss: 0.0982    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 52ms/step - accuracy: 0.9542 - loss: 0.0962 - val_accuracy: 0.9635 - val_loss: 0.1027
    Epoch 15/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 33ms/step - accuracy: 0.9577 - loss: 0.0953    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 44ms/step - accuracy: 0.9574 - loss: 0.0951 - val_accuracy: 0.9625 - val_loss: 0.0974
    Epoch 16/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 27ms/step - accuracy: 0.9521 - loss: 0.1010    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 34ms/step - accuracy: 0.9537 - loss: 0.0975 - val_accuracy: 0.9625 - val_loss: 0.0938
    Epoch 17/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 27ms/step - accuracy: 0.9539 - loss: 0.0970    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 35ms/step - accuracy: 0.9543 - loss: 0.0968 - val_accuracy: 0.9640 - val_loss: 0.0930
    Epoch 18/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 26ms/step - accuracy: 0.9571 - loss: 0.0884    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 35ms/step - accuracy: 0.9565 - loss: 0.0906 - val_accuracy: 0.9680 - val_loss: 0.0948
    Epoch 19/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 29ms/step - accuracy: 0.9555 - loss: 0.0946    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - accuracy: 0.9569 - loss: 0.0937 - val_accuracy: 0.9645 - val_loss: 0.0957
    Epoch 20/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 27ms/step - accuracy: 0.9593 - loss: 0.0872    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 35ms/step - accuracy: 0.9592 - loss: 0.0886 - val_accuracy: 0.9658 - val_loss: 0.0932




.. GENERATED FROM PYTHON SOURCE LINES 84-86

Plot training history
---------------------

.. GENERATED FROM PYTHON SOURCE LINES 86-88

.. code-block:: Python

    dense_net.plot_model_history(history)




.. image-sg:: /gallery/images/sphx_glr_classifier_autoencoder_002.png
   :alt: Loss, Accuracy
   :srcset: /gallery/images/sphx_glr_classifier_autoencoder_002.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 89-91

Predict and visualize on a test signal
--------------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 91-94

.. code-block:: Python

    dense_net.plot_prediction(
        signal=dataset.signals[0:1, :],
        threshold=0.4
    )


.. image-sg:: /gallery/images/sphx_glr_classifier_autoencoder_003.png
   :alt: Predicted Region of Interest
   :srcset: /gallery/images/sphx_glr_classifier_autoencoder_003.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    <Figure size 1200x500 with 1 Axes>




.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 36.646 seconds)


.. _sphx_glr_download_gallery_classifier_autoencoder.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: classifier_autoencoder.ipynb <classifier_autoencoder.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: classifier_autoencoder.py <classifier_autoencoder.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: classifier_autoencoder.zip <classifier_autoencoder.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
