
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "gallery/classifier_dense.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_gallery_classifier_dense.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_gallery_classifier_dense.py:


DenseNet Classifier: Detecting Regions of Interest in Synthetic Signals
=======================================================================

This example demonstrates how to use DeepPeak's DenseNet classifier to identify
regions of interest (ROIs) in synthetic 1D signals containing Gaussian peaks.

We will:
- Generate a dataset of noisy signals with random Gaussian peaks
- Build and train a DenseNet classifier to detect ROIs
- Visualize the training process and model predictions

.. note::
    This example is fully reproducible and suitable for Sphinx-Gallery documentation.

.. GENERATED FROM PYTHON SOURCE LINES 19-21

Imports and reproducibility
--------------------------

.. GENERATED FROM PYTHON SOURCE LINES 21-29

.. code-block:: Python

    import numpy as np

    from DeepPeak.machine_learning.classifier import DenseNet
    from DeepPeak.signals import SignalDatasetGenerator
    from DeepPeak import kernel

    np.random.seed(42)








.. GENERATED FROM PYTHON SOURCE LINES 30-32

Generate synthetic dataset
-------------------------

.. GENERATED FROM PYTHON SOURCE LINES 32-51

.. code-block:: Python

    NUM_PEAKS = 3
    SEQUENCE_LENGTH = 200

    kernel = kernel.Lorentzian(
        amplitude=(1, 20),
        position=(0.1, 0.9),
        width=(0.03, 0.05),
    )

    generator = SignalDatasetGenerator(n_samples=300, sequence_length=SEQUENCE_LENGTH)

    dataset = generator.generate(
        kernel=kernel,
        n_peaks=(1, NUM_PEAKS),
        noise_std=0.1,
        categorical_peak_count=False,
        compute_region_of_interest=True,
    )








.. GENERATED FROM PYTHON SOURCE LINES 52-54

Visualize a few example signals and their regions of interest
------------------------------------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 54-56

.. code-block:: Python

    dataset.plot(number_of_samples=3)




.. image-sg:: /gallery/images/sphx_glr_classifier_dense_001.png
   :alt: Predicted ROI (Sample 0), Predicted ROI (Sample 1), Predicted ROI (Sample 2)
   :srcset: /gallery/images/sphx_glr_classifier_dense_001.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    <Figure size 800x900 with 3 Axes>



.. GENERATED FROM PYTHON SOURCE LINES 57-59

Build and summarize the DenseNet classifier
------------------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 59-71

.. code-block:: Python

    dense_net = DenseNet(
        sequence_length=SEQUENCE_LENGTH,
        filters=(32, 64, 128),
        dilation_rates=(1, 2, 4),
        kernel_size=3,
        optimizer="adam",
        loss="binary_crossentropy",
        metrics=["accuracy"],
    )
    dense_net.build()
    dense_net.summary()





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Model: "DenseNetDetector"
    ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
    ┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
    ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
    │ input (InputLayer)              │ (None, 200, 1)         │             0 │
    ├─────────────────────────────────┼────────────────────────┼───────────────┤
    │ conv_0 (Conv1D)                 │ (None, 200, 32)        │           128 │
    ├─────────────────────────────────┼────────────────────────┼───────────────┤
    │ conv_1 (Conv1D)                 │ (None, 200, 64)        │         6,208 │
    ├─────────────────────────────────┼────────────────────────┼───────────────┤
    │ conv_2 (Conv1D)                 │ (None, 200, 128)       │        24,704 │
    ├─────────────────────────────────┼────────────────────────┼───────────────┤
    │ ROI (Conv1D)                    │ (None, 200, 1)         │           129 │
    └─────────────────────────────────┴────────────────────────┴───────────────┘
     Total params: 31,169 (121.75 KB)
     Trainable params: 31,169 (121.75 KB)
     Non-trainable params: 0 (0.00 B)




.. GENERATED FROM PYTHON SOURCE LINES 72-74

Train the classifier
--------------------

.. GENERATED FROM PYTHON SOURCE LINES 74-82

.. code-block:: Python

    history = dense_net.fit(
        dataset.signals,
        dataset.region_of_interest,
        validation_split=0.2,
        epochs=20,
        batch_size=64,
    )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Epoch 1/20
    1/4 ━━━━━━━━━━━━━━━━━━━━ 3s 1s/step - accuracy: 0.1511 - loss: 0.7219    3/4 ━━━━━━━━━━━━━━━━━━━━ 0s 25ms/step - accuracy: 0.4614 - loss: 0.6944
    Epoch 1: val_loss improved from None to 0.60602, saving model to /tmp/wavenet_ckpt_3_x3qng7/best.weights.h5
        4/4 ━━━━━━━━━━━━━━━━━━━━ 1s 98ms/step - accuracy: 0.7364 - loss: 0.6592 - val_accuracy: 0.9503 - val_loss: 0.6060
    Epoch 2/20
    1/4 ━━━━━━━━━━━━━━━━━━━━ 0s 37ms/step - accuracy: 0.9520 - loss: 0.6147    4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step - accuracy: 0.9508 - loss: 0.6096
    Epoch 2: val_loss improved from 0.60602 to 0.57643, saving model to /tmp/wavenet_ckpt_3_x3qng7/best.weights.h5
        4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 44ms/step - accuracy: 0.9502 - loss: 0.6042 - val_accuracy: 0.9503 - val_loss: 0.5764
    Epoch 3/20
    1/4 ━━━━━━━━━━━━━━━━━━━━ 0s 37ms/step - accuracy: 0.9506 - loss: 0.5960    4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step - accuracy: 0.9501 - loss: 0.5803
    Epoch 3: val_loss improved from 0.57643 to 0.52512, saving model to /tmp/wavenet_ckpt_3_x3qng7/best.weights.h5
        4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 43ms/step - accuracy: 0.9502 - loss: 0.5669 - val_accuracy: 0.9503 - val_loss: 0.5251
    Epoch 4/20
    1/4 ━━━━━━━━━━━━━━━━━━━━ 0s 38ms/step - accuracy: 0.9549 - loss: 0.5374    3/4 ━━━━━━━━━━━━━━━━━━━━ 0s 27ms/step - accuracy: 0.9524 - loss: 0.5285
    Epoch 4: val_loss improved from 0.52512 to 0.46661, saving model to /tmp/wavenet_ckpt_3_x3qng7/best.weights.h5
        4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 46ms/step - accuracy: 0.9502 - loss: 0.5133 - val_accuracy: 0.9503 - val_loss: 0.4666
    Epoch 5/20
    1/4 ━━━━━━━━━━━━━━━━━━━━ 0s 37ms/step - accuracy: 0.9474 - loss: 0.4779    4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step - accuracy: 0.9496 - loss: 0.4620
    Epoch 5: val_loss improved from 0.46661 to 0.39238, saving model to /tmp/wavenet_ckpt_3_x3qng7/best.weights.h5
        4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 43ms/step - accuracy: 0.9505 - loss: 0.4504 - val_accuracy: 0.9513 - val_loss: 0.3924
    Epoch 6/20
    1/4 ━━━━━━━━━━━━━━━━━━━━ 0s 37ms/step - accuracy: 0.9511 - loss: 0.3983    4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step - accuracy: 0.9525 - loss: 0.3850
    Epoch 6: val_loss improved from 0.39238 to 0.30514, saving model to /tmp/wavenet_ckpt_3_x3qng7/best.weights.h5
        4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 43ms/step - accuracy: 0.9551 - loss: 0.3724 - val_accuracy: 0.9709 - val_loss: 0.3051
    Epoch 7/20
    1/4 ━━━━━━━━━━━━━━━━━━━━ 0s 36ms/step - accuracy: 0.9670 - loss: 0.3068    4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step - accuracy: 0.9667 - loss: 0.2932
    Epoch 7: val_loss improved from 0.30514 to 0.20867, saving model to /tmp/wavenet_ckpt_3_x3qng7/best.weights.h5
        4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 43ms/step - accuracy: 0.9667 - loss: 0.2800 - val_accuracy: 0.9803 - val_loss: 0.2087
    Epoch 8/20
    1/4 ━━━━━━━━━━━━━━━━━━━━ 0s 37ms/step - accuracy: 0.9765 - loss: 0.2202    4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step - accuracy: 0.9770 - loss: 0.2038
    Epoch 8: val_loss improved from 0.20867 to 0.13636, saving model to /tmp/wavenet_ckpt_3_x3qng7/best.weights.h5
        4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 44ms/step - accuracy: 0.9766 - loss: 0.1904 - val_accuracy: 0.9808 - val_loss: 0.1364
    Epoch 9/20
    1/4 ━━━━━━━━━━━━━━━━━━━━ 0s 36ms/step - accuracy: 0.9798 - loss: 0.1420    4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step - accuracy: 0.9777 - loss: 0.1347
    Epoch 9: val_loss improved from 0.13636 to 0.09080, saving model to /tmp/wavenet_ckpt_3_x3qng7/best.weights.h5
        4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 44ms/step - accuracy: 0.9772 - loss: 0.1264 - val_accuracy: 0.9802 - val_loss: 0.0908
    Epoch 10/20
    1/4 ━━━━━━━━━━━━━━━━━━━━ 0s 36ms/step - accuracy: 0.9761 - loss: 0.0989    4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step - accuracy: 0.9766 - loss: 0.0943
    Epoch 10: val_loss improved from 0.09080 to 0.06963, saving model to /tmp/wavenet_ckpt_3_x3qng7/best.weights.h5
        4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 43ms/step - accuracy: 0.9769 - loss: 0.0894 - val_accuracy: 0.9799 - val_loss: 0.0696
    Epoch 11/20
    1/4 ━━━━━━━━━━━━━━━━━━━━ 0s 36ms/step - accuracy: 0.9752 - loss: 0.0830    4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step - accuracy: 0.9758 - loss: 0.0780
    Epoch 11: val_loss improved from 0.06963 to 0.06062, saving model to /tmp/wavenet_ckpt_3_x3qng7/best.weights.h5
        4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 43ms/step - accuracy: 0.9762 - loss: 0.0738 - val_accuracy: 0.9798 - val_loss: 0.0606
    Epoch 12/20
    1/4 ━━━━━━━━━━━━━━━━━━━━ 0s 37ms/step - accuracy: 0.9752 - loss: 0.0731    4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step - accuracy: 0.9763 - loss: 0.0688
    Epoch 12: val_loss improved from 0.06062 to 0.05846, saving model to /tmp/wavenet_ckpt_3_x3qng7/best.weights.h5
        4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 44ms/step - accuracy: 0.9770 - loss: 0.0654 - val_accuracy: 0.9793 - val_loss: 0.0585
    Epoch 13/20
    1/4 ━━━━━━━━━━━━━━━━━━━━ 0s 36ms/step - accuracy: 0.9742 - loss: 0.0733    4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step - accuracy: 0.9764 - loss: 0.0657
    Epoch 13: val_loss improved from 0.05846 to 0.05489, saving model to /tmp/wavenet_ckpt_3_x3qng7/best.weights.h5
        4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 44ms/step - accuracy: 0.9773 - loss: 0.0618 - val_accuracy: 0.9804 - val_loss: 0.0549
    Epoch 14/20
    1/4 ━━━━━━━━━━━━━━━━━━━━ 0s 37ms/step - accuracy: 0.9798 - loss: 0.0545    4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step - accuracy: 0.9781 - loss: 0.0592
    Epoch 14: val_loss improved from 0.05489 to 0.05439, saving model to /tmp/wavenet_ckpt_3_x3qng7/best.weights.h5
        4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 43ms/step - accuracy: 0.9776 - loss: 0.0599 - val_accuracy: 0.9797 - val_loss: 0.0544
    Epoch 15/20
    1/4 ━━━━━━━━━━━━━━━━━━━━ 0s 36ms/step - accuracy: 0.9771 - loss: 0.0606    4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step - accuracy: 0.9781 - loss: 0.0585
    Epoch 15: val_loss improved from 0.05439 to 0.05414, saving model to /tmp/wavenet_ckpt_3_x3qng7/best.weights.h5
        4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 43ms/step - accuracy: 0.9782 - loss: 0.0583 - val_accuracy: 0.9793 - val_loss: 0.0541
    Epoch 16/20
    1/4 ━━━━━━━━━━━━━━━━━━━━ 0s 37ms/step - accuracy: 0.9785 - loss: 0.0579    4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step - accuracy: 0.9783 - loss: 0.0577
    Epoch 16: val_loss improved from 0.05414 to 0.05123, saving model to /tmp/wavenet_ckpt_3_x3qng7/best.weights.h5
        4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 44ms/step - accuracy: 0.9777 - loss: 0.0576 - val_accuracy: 0.9812 - val_loss: 0.0512
    Epoch 17/20
    1/4 ━━━━━━━━━━━━━━━━━━━━ 0s 37ms/step - accuracy: 0.9802 - loss: 0.0540    4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step - accuracy: 0.9791 - loss: 0.0549
    Epoch 17: val_loss improved from 0.05123 to 0.05037, saving model to /tmp/wavenet_ckpt_3_x3qng7/best.weights.h5
        4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 43ms/step - accuracy: 0.9784 - loss: 0.0562 - val_accuracy: 0.9814 - val_loss: 0.0504
    Epoch 18/20
    1/4 ━━━━━━━━━━━━━━━━━━━━ 0s 37ms/step - accuracy: 0.9784 - loss: 0.0546    4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step - accuracy: 0.9790 - loss: 0.0545
    Epoch 18: val_loss improved from 0.05037 to 0.04901, saving model to /tmp/wavenet_ckpt_3_x3qng7/best.weights.h5
        4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 44ms/step - accuracy: 0.9790 - loss: 0.0551 - val_accuracy: 0.9822 - val_loss: 0.0490
    Epoch 19/20
    1/4 ━━━━━━━━━━━━━━━━━━━━ 0s 37ms/step - accuracy: 0.9755 - loss: 0.0612    4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step - accuracy: 0.9780 - loss: 0.0567
    Epoch 19: val_loss improved from 0.04901 to 0.04783, saving model to /tmp/wavenet_ckpt_3_x3qng7/best.weights.h5
        4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 44ms/step - accuracy: 0.9794 - loss: 0.0542 - val_accuracy: 0.9825 - val_loss: 0.0478
    Epoch 20/20
    1/4 ━━━━━━━━━━━━━━━━━━━━ 0s 37ms/step - accuracy: 0.9789 - loss: 0.0606    4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step - accuracy: 0.9790 - loss: 0.0565
    Epoch 20: val_loss improved from 0.04783 to 0.04727, saving model to /tmp/wavenet_ckpt_3_x3qng7/best.weights.h5
        4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 44ms/step - accuracy: 0.9799 - loss: 0.0533 - val_accuracy: 0.9823 - val_loss: 0.0473
    Restored best model weights from /tmp/wavenet_ckpt_3_x3qng7/best.weights.h5




.. GENERATED FROM PYTHON SOURCE LINES 83-85

Plot training history
---------------------

.. GENERATED FROM PYTHON SOURCE LINES 85-87

.. code-block:: Python

    dense_net.plot_model_history()




.. image-sg:: /gallery/images/sphx_glr_classifier_dense_002.png
   :alt: accuracy, loss, val_accuracy, val_loss
   :srcset: /gallery/images/sphx_glr_classifier_dense_002.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    <Figure size 800x1200 with 4 Axes>



.. GENERATED FROM PYTHON SOURCE LINES 88-90

Predict and visualize on a test signal
--------------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 90-91

.. code-block:: Python

    _ = dense_net.plot_prediction(dataset=dataset, number_of_samples=12, number_of_columns=3, threshold=0.1, randomize_signal=True)



.. image-sg:: /gallery/images/sphx_glr_classifier_dense_003.png
   :alt: Predicted ROI (Sample 2), Predicted ROI (Sample 195), Predicted ROI (Sample 91), Predicted ROI (Sample 198), Predicted ROI (Sample 123), Predicted ROI (Sample 223), Predicted ROI (Sample 101), Predicted ROI (Sample 139), Predicted ROI (Sample 55), Predicted ROI (Sample 70), Predicted ROI (Sample 83), Predicted ROI (Sample 7)
   :srcset: /gallery/images/sphx_glr_classifier_dense_003.png
   :class: sphx-glr-single-img






.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 9.123 seconds)


.. _sphx_glr_download_gallery_classifier_dense.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: classifier_dense.ipynb <classifier_dense.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: classifier_dense.py <classifier_dense.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: classifier_dense.zip <classifier_dense.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
