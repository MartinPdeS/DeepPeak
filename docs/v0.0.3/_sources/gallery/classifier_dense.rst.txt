
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "gallery/classifier_dense.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_gallery_classifier_dense.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_gallery_classifier_dense.py:


DenseNet Classifier: Detecting Regions of Interest in Synthetic Signals
=======================================================================

This example demonstrates how to use DeepPeak's DenseNet classifier to identify
regions of interest (ROIs) in synthetic 1D signals containing Gaussian peaks.

We will:
- Generate a dataset of noisy signals with random Gaussian peaks
- Build and train a DenseNet classifier to detect ROIs
- Visualize the training process and model predictions

.. note::
    This example is fully reproducible and suitable for Sphinx-Gallery documentation.

.. GENERATED FROM PYTHON SOURCE LINES 19-21

Imports and reproducibility
--------------------------

.. GENERATED FROM PYTHON SOURCE LINES 21-28

.. code-block:: Python

    import numpy as np

    from DeepPeak.machine_learning.classifier import DenseNet
    from DeepPeak.signals import Kernel, SignalDatasetGenerator

    np.random.seed(42)








.. GENERATED FROM PYTHON SOURCE LINES 29-31

Generate synthetic dataset
-------------------------

.. GENERATED FROM PYTHON SOURCE LINES 31-47

.. code-block:: Python

    NUM_PEAKS = 3
    SEQUENCE_LENGTH = 200

    generator = SignalDatasetGenerator(n_samples=100, sequence_length=SEQUENCE_LENGTH)

    dataset = generator.generate(
        signal_type=Kernel.GAUSSIAN,
        n_peaks=(1, NUM_PEAKS),
        amplitude=(1, 20),
        position=(0.1, 0.9),
        width=(0.03, 0.05),
        noise_std=0.1,
        categorical_peak_count=False,
        compute_region_of_interest=True,
    )








.. GENERATED FROM PYTHON SOURCE LINES 48-50

Visualize a few example signals and their regions of interest
------------------------------------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 50-52

.. code-block:: Python

    dataset.plot(number_of_samples=3)




.. image-sg:: /gallery/images/sphx_glr_classifier_dense_001.png
   :alt: classifier dense
   :srcset: /gallery/images/sphx_glr_classifier_dense_001.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    <Figure size 800x900 with 3 Axes>



.. GENERATED FROM PYTHON SOURCE LINES 53-55

Build and summarize the DenseNet classifier
------------------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 55-67

.. code-block:: Python

    dense_net = DenseNet(
        sequence_length=SEQUENCE_LENGTH,
        filters=(32, 64, 128),
        dilation_rates=(1, 2, 4),
        kernel_size=3,
        optimizer="adam",
        loss="binary_crossentropy",
        metrics=["accuracy"],
    )
    dense_net.build()
    dense_net.summary()





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Model: "DenseNetDetector"
    ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
    ┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
    ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
    │ input (InputLayer)              │ (None, 200, 1)         │             0 │
    ├─────────────────────────────────┼────────────────────────┼───────────────┤
    │ conv_0 (Conv1D)                 │ (None, 200, 32)        │           128 │
    ├─────────────────────────────────┼────────────────────────┼───────────────┤
    │ conv_1 (Conv1D)                 │ (None, 200, 64)        │         6,208 │
    ├─────────────────────────────────┼────────────────────────┼───────────────┤
    │ conv_2 (Conv1D)                 │ (None, 200, 128)       │        24,704 │
    ├─────────────────────────────────┼────────────────────────┼───────────────┤
    │ ROI (Conv1D)                    │ (None, 200, 1)         │           129 │
    └─────────────────────────────────┴────────────────────────┴───────────────┘
     Total params: 31,169 (121.75 KB)
     Trainable params: 31,169 (121.75 KB)
     Non-trainable params: 0 (0.00 B)




.. GENERATED FROM PYTHON SOURCE LINES 68-70

Train the classifier
--------------------

.. GENERATED FROM PYTHON SOURCE LINES 70-78

.. code-block:: Python

    history = dense_net.fit(
        dataset.signals,
        dataset.region_of_interest,
        validation_split=0.2,
        epochs=20,
        batch_size=64,
    )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Epoch 1/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step - accuracy: 0.3570 - loss: 0.6930    2/2 ━━━━━━━━━━━━━━━━━━━━ 1s 206ms/step - accuracy: 0.4765 - loss: 0.6878 - val_accuracy: 0.9613 - val_loss: 0.6569
    Epoch 2/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 39ms/step - accuracy: 0.9499 - loss: 0.6564    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 48ms/step - accuracy: 0.9496 - loss: 0.6558 - val_accuracy: 0.9613 - val_loss: 0.6337
    Epoch 3/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 36ms/step - accuracy: 0.9477 - loss: 0.6308    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 48ms/step - accuracy: 0.9496 - loss: 0.6275 - val_accuracy: 0.9613 - val_loss: 0.6119
    Epoch 4/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 36ms/step - accuracy: 0.9499 - loss: 0.6000    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.9496 - loss: 0.5979 - val_accuracy: 0.9613 - val_loss: 0.5908
    Epoch 5/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 36ms/step - accuracy: 0.9495 - loss: 0.5739    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.9496 - loss: 0.5726 - val_accuracy: 0.9613 - val_loss: 0.5625
    Epoch 6/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 39ms/step - accuracy: 0.9492 - loss: 0.5427    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.9496 - loss: 0.5425 - val_accuracy: 0.9613 - val_loss: 0.5287
    Epoch 7/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 36ms/step - accuracy: 0.9491 - loss: 0.5128    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.9496 - loss: 0.5106 - val_accuracy: 0.9613 - val_loss: 0.4916
    Epoch 8/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 36ms/step - accuracy: 0.9484 - loss: 0.4763    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 48ms/step - accuracy: 0.9502 - loss: 0.4726 - val_accuracy: 0.9690 - val_loss: 0.4516
    Epoch 9/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 36ms/step - accuracy: 0.9613 - loss: 0.4350    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.9618 - loss: 0.4309 - val_accuracy: 0.9673 - val_loss: 0.4066
    Epoch 10/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 36ms/step - accuracy: 0.9610 - loss: 0.3918    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.9614 - loss: 0.3878 - val_accuracy: 0.9798 - val_loss: 0.3588
    Epoch 11/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 92ms/step - accuracy: 0.9716 - loss: 0.3458    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.9718 - loss: 0.3415 - val_accuracy: 0.9750 - val_loss: 0.3056
    Epoch 12/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 37ms/step - accuracy: 0.9671 - loss: 0.2977    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.9672 - loss: 0.2931 - val_accuracy: 0.9765 - val_loss: 0.2529
    Epoch 13/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 37ms/step - accuracy: 0.9675 - loss: 0.2503    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 48ms/step - accuracy: 0.9681 - loss: 0.2448 - val_accuracy: 0.9788 - val_loss: 0.2054
    Epoch 14/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 37ms/step - accuracy: 0.9689 - loss: 0.2077    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 48ms/step - accuracy: 0.9701 - loss: 0.2016 - val_accuracy: 0.9693 - val_loss: 0.1634
    Epoch 15/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 37ms/step - accuracy: 0.9647 - loss: 0.1668    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 48ms/step - accuracy: 0.9643 - loss: 0.1660 - val_accuracy: 0.9775 - val_loss: 0.1299
    Epoch 16/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 35ms/step - accuracy: 0.9698 - loss: 0.1352    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 48ms/step - accuracy: 0.9681 - loss: 0.1369 - val_accuracy: 0.9750 - val_loss: 0.1039
    Epoch 17/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 37ms/step - accuracy: 0.9673 - loss: 0.1150    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.9682 - loss: 0.1134 - val_accuracy: 0.9783 - val_loss: 0.0867
    Epoch 18/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 36ms/step - accuracy: 0.9682 - loss: 0.0991    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.9679 - loss: 0.0988 - val_accuracy: 0.9788 - val_loss: 0.0751
    Epoch 19/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 37ms/step - accuracy: 0.9720 - loss: 0.0850    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 48ms/step - accuracy: 0.9711 - loss: 0.0876 - val_accuracy: 0.9790 - val_loss: 0.0684
    Epoch 20/20
    1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 36ms/step - accuracy: 0.9682 - loss: 0.0858    2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.9696 - loss: 0.0816 - val_accuracy: 0.9798 - val_loss: 0.0641




.. GENERATED FROM PYTHON SOURCE LINES 79-81

Plot training history
---------------------

.. GENERATED FROM PYTHON SOURCE LINES 81-83

.. code-block:: Python

    dense_net.plot_model_history()




.. image-sg:: /gallery/images/sphx_glr_classifier_dense_002.png
   :alt: accuracy, loss, val_accuracy, val_loss
   :srcset: /gallery/images/sphx_glr_classifier_dense_002.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 84-86

Predict and visualize on a test signal
--------------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 86-87

.. code-block:: Python

    dense_net.plot_prediction(signal=dataset.signals[0:1, :], threshold=0.4)



.. image-sg:: /gallery/images/sphx_glr_classifier_dense_003.png
   :alt: Predicted Region of Interest
   :srcset: /gallery/images/sphx_glr_classifier_dense_003.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    <Figure size 1200x500 with 1 Axes>




.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 4.379 seconds)


.. _sphx_glr_download_gallery_classifier_dense.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: classifier_dense.ipynb <classifier_dense.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: classifier_dense.py <classifier_dense.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: classifier_dense.zip <classifier_dense.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
